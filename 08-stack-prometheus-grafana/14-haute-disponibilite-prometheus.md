üîù Retour au [Sommaire](/SOMMAIRE.md)

# 8.14 Haute Disponibilit√© Prometheus

## Introduction √† la haute disponibilit√©

La haute disponibilit√© (HA) pour Prometheus signifie s'assurer que votre syst√®me de monitoring continue de fonctionner m√™me en cas de panne d'un composant. Dans un environnement de production, perdre votre monitoring est critique car vous devenez "aveugle" sur l'√©tat de vos applications. M√™me dans un lab personnel, comprendre et impl√©menter la haute disponibilit√© est un excellent apprentissage qui vous pr√©pare aux environnements professionnels.

Imaginez que votre instance Prometheus tombe en panne pendant que vous testez une nouvelle application. Sans haute disponibilit√©, vous perdez non seulement le monitoring en temps r√©el, mais potentiellement aussi l'historique des m√©triques si le stockage est corrompu. Avec une configuration HA, une autre instance prend automatiquement le relais.

## Pourquoi la haute disponibilit√© dans un lab personnel ?

### Apprentissage et exp√©rimentation
Mettre en place une architecture HA dans votre lab MicroK8s vous permet de :
- Comprendre les concepts de r√©silience et de redondance
- Exp√©rimenter avec des architectures complexes sans risque
- Acqu√©rir des comp√©tences valoris√©es en entreprise
- Tester des sc√©narios de panne de mani√®re contr√¥l√©e

### Continuit√© du monitoring
M√™me dans un lab, vous pouvez avoir :
- Des applications personnelles importantes √† surveiller
- Des tests de longue dur√©e n√©cessitant un monitoring continu
- Des d√©monstrations ou pr√©sentations n√©cessitant de la fiabilit√©
- Un historique de m√©triques que vous ne voulez pas perdre

### Pr√©paration aux environnements r√©els
Les concepts que vous apprenez s'appliquent directement aux environnements de production o√π la haute disponibilit√© est cruciale.

## Architectures de haute disponibilit√© pour Prometheus

### Architecture de base : Duplication simple

La forme la plus simple de HA consiste √† faire fonctionner deux instances Prometheus identiques qui collectent les m√™mes m√©triques :

```yaml
# prometheus-instance-1.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: prometheus-1
  namespace: observability
spec:
  serviceName: prometheus-1
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
      instance: primary
  template:
    metadata:
      labels:
        app: prometheus
        instance: primary
    spec:
      containers:
      - name: prometheus
        image: prom/prometheus:v2.45.0
        args:
          - '--config.file=/etc/prometheus/prometheus.yml'
          - '--storage.tsdb.path=/prometheus'
          - '--storage.tsdb.retention.time=30d'
          - '--web.external-url=http://prometheus-1.observability.svc.cluster.local:9090'
        ports:
        - containerPort: 9090
          name: web
        volumeMounts:
        - name: config
          mountPath: /etc/prometheus
        - name: storage
          mountPath: /prometheus
      volumes:
      - name: config
        configMap:
          name: prometheus-config
  volumeClaimTemplates:
  - metadata:
      name: storage
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
```

La deuxi√®me instance serait identique, mais avec un nom diff√©rent :

```yaml
# prometheus-instance-2.yaml
# (M√™me configuration mais avec prometheus-2 comme nom)
```

### Architecture f√©d√©r√©e

La f√©d√©ration Prometheus permet de cr√©er une hi√©rarchie d'instances o√π un Prometheus "global" agr√®ge les donn√©es de plusieurs Prometheus "locaux" :

```yaml
# Configuration pour Prometheus global
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-global-config
  namespace: observability
data:
  prometheus.yml: |
    global:
      scrape_interval: 60s
      evaluation_interval: 60s

    scrape_configs:
      # F√©d√©ration depuis les instances locales
      - job_name: 'federate'
        scrape_interval: 15s
        honor_labels: true
        metrics_path: '/federate'
        params:
          'match[]':
            - '{job=~".*"}'  # R√©cup√®re toutes les m√©triques
            # Ou soyez plus s√©lectif :
            # - '{__name__=~"job:.*"}' # Seulement les recording rules
            # - '{__name__=~"ALERTS"}' # Seulement les alertes
        static_configs:
          - targets:
            - 'prometheus-1.observability.svc.cluster.local:9090'
            - 'prometheus-2.observability.svc.cluster.local:9090'
```

### Architecture avec Thanos

Thanos est une solution open source qui ajoute la haute disponibilit√© et le stockage √† long terme √† Prometheus. C'est l'approche la plus robuste mais aussi la plus complexe :

```yaml
# thanos-sidecar.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: prometheus-with-thanos
  namespace: observability
spec:
  serviceName: prometheus-thanos
  replicas: 2
  selector:
    matchLabels:
      app: prometheus-thanos
  template:
    metadata:
      labels:
        app: prometheus-thanos
    spec:
      containers:
      # Container Prometheus
      - name: prometheus
        image: prom/prometheus:v2.45.0
        args:
          - '--config.file=/etc/prometheus/prometheus.yml'
          - '--storage.tsdb.path=/prometheus'
          - '--storage.tsdb.retention.time=2h'  # R√©tention courte avec Thanos
          - '--storage.tsdb.min-block-duration=2h'
          - '--storage.tsdb.max-block-duration=2h'
          - '--web.enable-lifecycle'
        ports:
        - containerPort: 9090
          name: web
        volumeMounts:
        - name: config
          mountPath: /etc/prometheus
        - name: storage
          mountPath: /prometheus

      # Sidecar Thanos
      - name: thanos-sidecar
        image: quay.io/thanos/thanos:v0.32.0
        args:
          - 'sidecar'
          - '--tsdb.path=/prometheus'
          - '--prometheus.url=http://localhost:9090'
          - '--grpc-address=0.0.0.0:10901'
          - '--http-address=0.0.0.0:10902'
          - '--objstore.config-file=/etc/thanos/objstore.yml'
        ports:
        - containerPort: 10901
          name: grpc
        - containerPort: 10902
          name: http
        volumeMounts:
        - name: storage
          mountPath: /prometheus
        - name: thanos-config
          mountPath: /etc/thanos

      volumes:
      - name: config
        configMap:
          name: prometheus-config
      - name: thanos-config
        secret:
          secretName: thanos-objstore-config

  volumeClaimTemplates:
  - metadata:
      name: storage
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
```

## Configuration du stockage pour la haute disponibilit√©

### Stockage local r√©pliqu√©

Pour un lab MicroK8s, vous pouvez utiliser le stockage local avec r√©plication manuelle :

```yaml
# Configuration de volumes persistants pour chaque instance
apiVersion: v1
kind: PersistentVolume
metadata:
  name: prometheus-pv-1
spec:
  capacity:
    storage: 20Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-storage
  local:
    path: /data/prometheus-1
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - node-1
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: prometheus-pv-2
spec:
  capacity:
    storage: 20Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-storage
  local:
    path: /data/prometheus-2
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - node-2
```

### Stockage objet avec MinIO

Pour Thanos, vous avez besoin d'un stockage objet. MinIO est parfait pour un lab :

```yaml
# minio-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: minio
  namespace: observability
spec:
  replicas: 1
  selector:
    matchLabels:
      app: minio
  template:
    metadata:
      labels:
        app: minio
    spec:
      containers:
      - name: minio
        image: minio/minio:latest
        args:
          - server
          - /data
          - --console-address
          - ":9001"
        env:
        - name: MINIO_ROOT_USER
          value: "admin"
        - name: MINIO_ROOT_PASSWORD
          value: "changeme123"
        ports:
        - containerPort: 9000
          name: api
        - containerPort: 9001
          name: console
        volumeMounts:
        - name: storage
          mountPath: /data
      volumes:
      - name: storage
        persistentVolumeClaim:
          claimName: minio-pvc
---
# Configuration Thanos pour utiliser MinIO
apiVersion: v1
kind: Secret
metadata:
  name: thanos-objstore-config
  namespace: observability
stringData:
  objstore.yml: |
    type: S3
    config:
      bucket: thanos
      endpoint: minio.observability.svc.cluster.local:9000
      access_key: admin
      secret_key: changeme123
      insecure: true
```

## Load Balancing et d√©couverte de service

### Configuration avec MetalLB

Pour exposer vos instances Prometheus de mani√®re √©quilibr√©e :

```yaml
# service-loadbalancer.yaml
apiVersion: v1
kind: Service
metadata:
  name: prometheus-lb
  namespace: observability
  annotations:
    metallb.universe.tf/loadBalancerIPs: 192.168.1.100
spec:
  type: LoadBalancer
  selector:
    app: prometheus
  ports:
  - port: 9090
    targetPort: 9090
    protocol: TCP
---
# Endpoints pour les deux instances
apiVersion: v1
kind: Endpoints
metadata:
  name: prometheus-lb
  namespace: observability
subsets:
  - addresses:
    - ip: 10.1.1.10  # IP du pod prometheus-1
    - ip: 10.1.1.11  # IP du pod prometheus-2
    ports:
    - port: 9090
```

### Service Discovery automatique

Configuration pour d√©couvrir automatiquement les instances Prometheus :

```yaml
# Configuration dans prometheus.yml
scrape_configs:
  - job_name: 'prometheus-instances'
    kubernetes_sd_configs:
    - role: pod
      namespaces:
        names:
        - observability
    relabel_configs:
    - source_labels: [__meta_kubernetes_pod_label_app]
      action: keep
      regex: prometheus
    - source_labels: [__meta_kubernetes_pod_name]
      target_label: instance
    - source_labels: [__meta_kubernetes_namespace]
      target_label: namespace
```

## Gestion des alertes en haute disponibilit√©

### Alertmanager en cluster

Pour √©viter les alertes dupliqu√©es, configurez Alertmanager en mode cluster :

```yaml
# alertmanager-ha.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: alertmanager
  namespace: observability
spec:
  serviceName: alertmanager-ha
  replicas: 3  # Nombre impair pour le consensus
  selector:
    matchLabels:
      app: alertmanager
  template:
    metadata:
      labels:
        app: alertmanager
    spec:
      containers:
      - name: alertmanager
        image: prom/alertmanager:v0.26.0
        args:
          - '--config.file=/etc/alertmanager/config.yml'
          - '--storage.path=/alertmanager'
          - '--cluster.listen-address=0.0.0.0:9094'
          - '--cluster.peer=alertmanager-0.alertmanager-ha.observability.svc.cluster.local:9094'
          - '--cluster.peer=alertmanager-1.alertmanager-ha.observability.svc.cluster.local:9094'
          - '--cluster.peer=alertmanager-2.alertmanager-ha.observability.svc.cluster.local:9094'
        ports:
        - containerPort: 9093
          name: web
        - containerPort: 9094
          name: cluster
        volumeMounts:
        - name: config
          mountPath: /etc/alertmanager
        - name: storage
          mountPath: /alertmanager
      volumes:
      - name: config
        configMap:
          name: alertmanager-config
  volumeClaimTemplates:
  - metadata:
      name: storage
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 1Gi
```

### D√©duplication des alertes

Configuration pour √©viter les alertes multiples :

```yaml
# Dans alertmanager config
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: observability
data:
  config.yml: |
    global:
      resolve_timeout: 5m

    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 12h
      receiver: 'default'

    inhibit_rules:
      # Supprime les alertes de faible priorit√© si critique
      - source_match:
          severity: 'critical'
        target_match:
          severity: 'warning'
        equal: ['alertname', 'namespace', 'pod']

    receivers:
    - name: 'default'
      webhook_configs:
      - url: 'http://notification-service.observability.svc.cluster.local/webhook'
        send_resolved: true
```

## Synchronisation et coh√©rence des donn√©es

### Configuration de la synchronisation temporelle

La synchronisation temporelle est cruciale pour la coh√©rence des m√©triques :

```yaml
# ntp-daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: ntp-sync
  namespace: kube-system
spec:
  selector:
    matchLabels:
      name: ntp-sync
  template:
    metadata:
      labels:
        name: ntp-sync
    spec:
      hostNetwork: true
      hostPID: true
      containers:
      - name: ntp
        image: tutum/ntpd:latest
        securityContext:
          privileged: true
        env:
        - name: NTP_SERVERS
          value: "0.pool.ntp.org,1.pool.ntp.org,2.pool.ntp.org"
```

### Validation de la coh√©rence

Script pour v√©rifier la coh√©rence entre instances :

```yaml
# prometheus-consistency-check.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: consistency-check
  namespace: observability
data:
  check.sh: |
    #!/bin/bash

    # R√©cup√©ration d'une m√©trique test depuis les deux instances
    METRIC="up"
    TIME=$(date +%s)

    # Requ√™te sur instance 1
    RESULT1=$(curl -s "http://prometheus-1:9090/api/v1/query?query=${METRIC}&time=${TIME}")

    # Requ√™te sur instance 2
    RESULT2=$(curl -s "http://prometheus-2:9090/api/v1/query?query=${METRIC}&time=${TIME}")

    # Comparaison des r√©sultats
    if [ "$RESULT1" = "$RESULT2" ]; then
      echo "‚úì Les instances sont synchronis√©es"
    else
      echo "‚úó Divergence d√©tect√©e entre les instances"
      echo "Instance 1: $RESULT1"
      echo "Instance 2: $RESULT2"
    fi
```

## Grafana avec sources multiples

### Configuration de Grafana pour la HA

Configurez Grafana pour utiliser plusieurs sources Prometheus :

```yaml
# grafana-datasources.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-datasources
  namespace: observability
data:
  prometheus.yaml: |
    apiVersion: 1
    datasources:
    # Instance principale
    - name: Prometheus-Primary
      type: prometheus
      access: proxy
      url: http://prometheus-1.observability.svc.cluster.local:9090
      isDefault: true
      editable: false

    # Instance secondaire
    - name: Prometheus-Secondary
      type: prometheus
      access: proxy
      url: http://prometheus-2.observability.svc.cluster.local:9090
      editable: false

    # Load balancer (utilise automatiquement une instance disponible)
    - name: Prometheus-HA
      type: prometheus
      access: proxy
      url: http://prometheus-lb.observability.svc.cluster.local:9090
      editable: false

    # Thanos Query (si utilis√©)
    - name: Thanos
      type: prometheus
      access: proxy
      url: http://thanos-query.observability.svc.cluster.local:9090
      editable: false
```

### Variables de dashboard pour la s√©lection de source

Dans vos dashboards Grafana, cr√©ez une variable pour basculer entre les sources :

```json
{
  "templating": {
    "list": [
      {
        "name": "datasource",
        "type": "datasource",
        "query": "prometheus",
        "current": {
          "text": "Prometheus-HA",
          "value": "Prometheus-HA"
        },
        "refresh": 1,
        "regex": "",
        "multi": false,
        "includeAll": false
      }
    ]
  }
}
```

## Tests de r√©silience

### Simulation de pannes

Scripts pour tester votre configuration HA :

```yaml
# chaos-engineering.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: prometheus-chaos-test
  namespace: observability
spec:
  template:
    spec:
      containers:
      - name: chaos
        image: busybox
        command:
        - /bin/sh
        - -c
        - |
          echo "Test 1: Arr√™t de prometheus-1"
          kubectl delete pod prometheus-1-0 -n observability
          sleep 30

          echo "Test 2: V√©rification que prometheus-2 continue"
          wget -O- http://prometheus-2:9090/api/v1/query?query=up

          echo "Test 3: Attente du red√©marrage de prometheus-1"
          kubectl wait --for=condition=ready pod/prometheus-1-0 -n observability --timeout=300s

          echo "Tests termin√©s avec succ√®s"
      restartPolicy: Never
```

### Validation de la r√©cup√©ration

Test automatis√© de r√©cup√©ration apr√®s panne :

```yaml
# recovery-test.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: recovery-test
  namespace: observability
data:
  test.sh: |
    #!/bin/bash

    # Fonction de test de disponibilit√©
    check_prometheus() {
      local instance=$1
      curl -s -o /dev/null -w "%{http_code}" \
        "http://${instance}:9090/api/v1/query?query=up"
    }

    # Test de basculement
    echo "√âtat initial:"
    echo "Prometheus-1: $(check_prometheus prometheus-1)"
    echo "Prometheus-2: $(check_prometheus prometheus-2)"

    # Simulation de panne
    echo "Simulation panne prometheus-1..."
    kubectl scale statefulset prometheus-1 --replicas=0 -n observability

    sleep 10

    # V√©rification du basculement
    echo "Apr√®s panne:"
    echo "Prometheus-1: $(check_prometheus prometheus-1)"
    echo "Prometheus-2: $(check_prometheus prometheus-2)"

    # Restauration
    echo "Restauration prometheus-1..."
    kubectl scale statefulset prometheus-1 --replicas=1 -n observability

    # Attente de la r√©cup√©ration
    kubectl wait --for=condition=ready pod/prometheus-1-0 -n observability

    echo "Apr√®s r√©cup√©ration:"
    echo "Prometheus-1: $(check_prometheus prometheus-1)"
    echo "Prometheus-2: $(check_prometheus prometheus-2)"
```

## Optimisation pour un lab personnel

### Configuration minimale HA

Pour un lab avec ressources limit√©es, voici une configuration HA minimale :

```yaml
# prometheus-ha-minimal.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-ha-config
  namespace: observability
data:
  prometheus.yml: |
    global:
      scrape_interval: 30s  # Intervalle plus long pour √©conomiser les ressources
      evaluation_interval: 30s
      external_labels:
        replica: $(POD_NAME)  # Identifie chaque r√©plique

    # Configuration minimale de scraping
    scrape_configs:
      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
        - role: pod
        relabel_configs:
        # Scrape seulement les pods avec annotation
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
          action: keep
          regex: true
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus-ha
  namespace: observability
spec:
  replicas: 2  # Seulement 2 r√©pliques pour un lab
  selector:
    matchLabels:
      app: prometheus-ha
  template:
    metadata:
      labels:
        app: prometheus-ha
    spec:
      containers:
      - name: prometheus
        image: prom/prometheus:v2.45.0
        resources:
          requests:
            memory: "512Mi"  # Ressources minimales
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        args:
          - '--config.file=/etc/prometheus/prometheus.yml'
          - '--storage.tsdb.path=/prometheus'
          - '--storage.tsdb.retention.time=7d'  # R√©tention courte
          - '--storage.tsdb.wal-compression'  # Compression WAL
        volumeMounts:
        - name: config
          mountPath: /etc/prometheus
        - name: storage
          mountPath: /prometheus
      volumes:
      - name: config
        configMap:
          name: prometheus-ha-config
      - name: storage
        emptyDir:
          sizeLimit: 5Gi  # Stockage limit√©
```

### Monitoring de la HA elle-m√™me

Dashboard pour surveiller votre configuration HA :

```yaml
# Requ√™tes PromQL pour votre dashboard HA
apiVersion: v1
kind: ConfigMap
metadata:
  name: ha-dashboard-queries
  namespace: observability
data:
  queries.txt: |
    # Nombre d'instances Prometheus actives
    count(up{job="prometheus"})

    # Temps depuis le dernier scrape par instance
    time() - prometheus_target_last_scrape_timestamp_seconds

    # Divergence de m√©triques entre instances
    stddev by (metric) (
      prometheus_tsdb_symbol_table_size_bytes
    )

    # Utilisation m√©moire par instance
    process_resident_memory_bytes{job="prometheus"}

    # Latence de scraping
    prometheus_target_scrape_duration_seconds{quantile="0.99"}

    # √âtat de synchronisation Alertmanager
    alertmanager_cluster_members

    # Alertes actives par instance
    count by (replica) (ALERTS)
```

## D√©pannage de la haute disponibilit√©

### Probl√®mes courants et solutions

**Les instances ne se synchronisent pas**
- V√©rifiez la configuration r√©seau entre les pods
- Assurez-vous que les horloges sont synchronis√©es
- Contr√¥lez les labels `external_labels` dans la configuration

**Performances d√©grad√©es avec HA**
- R√©duisez la fr√©quence de scraping
- Limitez le nombre de m√©triques avec des relabel_configs
- Utilisez des recording rules pour les calculs lourds

**Stockage qui se remplit rapidement**
- Ajustez la r√©tention (`--storage.tsdb.retention.time`)
- Activez la compression WAL
- Configurez le compactage plus agressif

**Alertes dupliqu√©es**
- V√©rifiez la configuration du cluster Alertmanager
- Ajustez les param√®tres `group_wait` et `group_interval`
- Utilisez les `inhibit_rules` correctement

### Commandes de diagnostic

```bash
# V√©rifier l'√©tat des instances Prometheus
kubectl get pods -n observability -l app=prometheus

# Logs d'une instance sp√©cifique
kubectl logs -n observability prometheus-1-0 --tail=50

# M√©triques internes de Prometheus
kubectl port-forward -n observability prometheus-1-0 9090:9090
curl localhost:9090/metrics | grep prometheus_

# √âtat du cluster Alertmanager
kubectl exec -n observability alertmanager-0 -- \
  amtool cluster show

# V√©rifier la coh√©rence des donn√©es
for i in 1 2; do
  echo "Instance prometheus-$i:"
  kubectl exec -n observability prometheus-$i-0 -- \
    promtool query instant \
    'http://localhost:9090' \
    'up{job="kubernetes-nodes"}'
done
```

## Migration vers une architecture HA

### Plan de migration depuis une instance unique

Si vous avez d√©j√† Prometheus en fonctionnement, voici comment migrer vers HA :

```yaml
# √âtape 1: Backup de la configuration existante
apiVersion: batch/v1
kind: Job
metadata:
  name: prometheus-backup
  namespace: observability
spec:
  template:
    spec:
      containers:
      - name: backup
        image: busybox
        command:
        - /bin/sh
        - -c
        - |
          # Sauvegarde de la configuration
          kubectl get configmap prometheus-config -n observability -o yaml > /backup/config.yaml

          # Sauvegarde des donn√©es TSDB
          kubectl exec prometheus-0 -n observability -- tar czf - /prometheus > /backup/prometheus-data.tar.gz

          echo "Backup termin√©"
        volumeMounts:
        - name: backup
          mountPath: /backup
      volumes:
      - name: backup
        persistentVolumeClaim:
          claimName: backup-pvc
      restartPolicy: Never
```

### Checklist de migration

Avant de passer en HA, v√©rifiez :

1. **Ressources disponibles**
   - Au moins 2x les ressources CPU/RAM actuelles
   - Espace disque suffisant pour les r√©pliques

2. **Configuration r√©seau**
   - Communication inter-pods fonctionnelle
   - Load balancer ou service de type ClusterIP configur√©

3. **Donn√©es existantes**
   - Backup complet effectu√©
   - Plan de migration des donn√©es historiques

4. **Tests**
   - Environment de test disponible
   - Proc√©dures de rollback document√©es

## Bonnes pratiques pour la HA dans un lab

### Dimensionnement appropri√©

Pour un lab personnel, adaptez les ressources :

```yaml
# Recommandations pour un lab
Small Lab (1-10 services):
  - 2 instances Prometheus
  - 512MB RAM par instance
  - 5GB stockage par instance
  - R√©tention: 7 jours

Medium Lab (10-50 services):
  - 2-3 instances Prometheus
  - 1GB RAM par instance
  - 10GB stockage par instance
  - R√©tention: 15 jours

Large Lab (50+ services):
  - 3 instances Prometheus
  - 2GB RAM par instance
  - 20GB stockage par instance
  - R√©tention: 30 jours
  - Consid√©rez Thanos
```

### Automatisation et maintenance

Scripts de maintenance automatis√©e :

```yaml
# cronjob-maintenance.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: prometheus-ha-maintenance
  namespace: observability
spec:
  schedule: "0 2 * * 0"  # Chaque dimanche √† 2h
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: maintenance
            image: prom/prometheus:v2.45.0
            command:
            - /bin/sh
            - -c
            - |
              # Compactage des donn√©es TSDB
              for i in 0 1; do
                echo "Compactage prometheus-$i"
                kubectl exec prometheus-$i-0 -n observability -- \
                  promtool tsdb compact /prometheus
              done

              # Nettoyage des m√©triques obsol√®tes
              kubectl exec prometheus-0-0 -n observability -- \
                curl -X POST http://localhost:9090/api/v1/admin/tsdb/clean_tombstones

              echo "Maintenance termin√©e"
          restartPolicy: OnFailure
```

## Conclusion

La haute disponibilit√© de Prometheus dans un lab MicroK8s est un excellent moyen d'apprendre les concepts de r√©silience et de redondance applicables en production. M√™me avec des ressources limit√©es, vous pouvez impl√©menter une architecture HA fonctionnelle qui vous permettra de :

- Maintenir votre monitoring op√©rationnel en cas de panne
- Exp√©rimenter avec des architectures complexes
- Pr√©parer vos comp√©tences pour des environnements professionnels
- Garantir la continuit√© de vos m√©triques importantes

Commencez par une configuration simple avec deux instances Prometheus, puis √©voluez progressivement vers des architectures plus sophistiqu√©es comme Thanos quand vos besoins et vos ressources le permettent.

## √âvolution progressive de votre architecture HA

### Roadmap de maturit√© HA

Voici un chemin d'√©volution recommand√© pour votre lab :

**Phase 1 : Duplication simple (Semaines 1-2)**
- Deux instances Prometheus identiques
- Scraping des m√™mes targets
- Grafana avec les deux sources configur√©es
- Test manuel de basculement

**Phase 2 : Load balancing (Semaines 3-4)**
- Ajout d'un service LoadBalancer
- Configuration de health checks
- Basculement automatique en cas de panne
- Monitoring de la disponibilit√©

**Phase 3 : Alerting HA (Semaines 5-6)**
- Cluster Alertmanager √† 3 n≈ìuds
- D√©duplication des alertes
- Tests de r√©silience automatis√©s
- Documentation des proc√©dures

**Phase 4 : Stockage distribu√© (Mois 2)**
- Introduction de Thanos ou Cortex
- Stockage objet avec MinIO
- Requ√™tes globales cross-instances
- R√©tention long terme

**Phase 5 : Automatisation compl√®te (Mois 3)**
- GitOps pour la configuration
- Tests de chaos engineering
- Auto-healing avec operators
- Dashboards de sant√© HA

### M√©triques de succ√®s HA

Indicateurs pour mesurer l'efficacit√© de votre HA :

```yaml
# Requ√™tes PromQL pour mesurer la HA
apiVersion: v1
kind: ConfigMap
metadata:
  name: ha-sli-queries
  namespace: observability
data:
  sli.yml: |
    # Disponibilit√© du service (SLI)
    - name: prometheus_availability
      query: |
        avg_over_time(
          (count(up{job="prometheus"} == 1) >= 1)[5m:]
        ) * 100
      target: 99.9  # Objectif de disponibilit√©

    # Temps de r√©cup√©ration apr√®s incident
    - name: mean_time_to_recovery
      query: |
        histogram_quantile(0.5,
          rate(prometheus_recovery_duration_seconds_bucket[7d])
        )
      target: 300  # MTTR cible en secondes

    # Coh√©rence des donn√©es entre instances
    - name: data_consistency
      query: |
        1 - (
          stddev by (metric) (prometheus_tsdb_symbol_table_size_bytes)
          /
          avg by (metric) (prometheus_tsdb_symbol_table_size_bytes)
        ) * 100
      target: 99  # % de coh√©rence cible

    # Latence de requ√™te en HA
    - name: query_latency_p99
      query: |
        histogram_quantile(0.99,
          rate(prometheus_engine_query_duration_seconds_bucket[5m])
        )
      target: 1  # Latence max en secondes
```

## Sc√©narios avanc√©s de test

### Test de split-brain

Simulation d'une partition r√©seau (split-brain) :

```yaml
# network-partition-test.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: split-brain-test
  namespace: observability
data:
  test.sh: |
    #!/bin/bash

    echo "=== Test de Split-Brain Prometheus HA ==="

    # Fonction pour isoler un pod r√©seau
    isolate_pod() {
      local pod=$1
      echo "Isolation r√©seau de $pod..."

      # Ajout de r√®gles iptables pour bloquer le trafic
      kubectl exec -n observability $pod -- sh -c "
        iptables -A INPUT -s 10.0.0.0/8 -j DROP
        iptables -A OUTPUT -d 10.0.0.0/8 -j DROP
      "
    }

    # Fonction pour restaurer la connectivit√©
    restore_pod() {
      local pod=$1
      echo "Restauration r√©seau de $pod..."

      kubectl exec -n observability $pod -- sh -c "
        iptables -D INPUT -s 10.0.0.0/8 -j DROP
        iptables -D OUTPUT -d 10.0.0.0/8 -j DROP
      "
    }

    # Test 1: Isolation d'une instance
    echo "Test 1: Isolation de prometheus-1..."
    isolate_pod "prometheus-1-0"

    sleep 30

    # V√©rification que prometheus-2 continue
    echo "V√©rification de prometheus-2..."
    STATUS=$(curl -s -o /dev/null -w "%{http_code}" http://prometheus-2:9090/api/v1/query?query=up)
    if [ "$STATUS" = "200" ]; then
      echo "‚úì Prometheus-2 fonctionne correctement"
    else
      echo "‚úó Prometheus-2 ne r√©pond pas"
    fi

    # V√©rification des divergences de donn√©es
    echo "Attente pour cr√©er une divergence..."
    sleep 60

    # Restauration
    restore_pod "prometheus-1-0"

    echo "Test de split-brain termin√©"
```

### Test de saturation des ressources

Simulation de saturation CPU/m√©moire :

```yaml
# stress-test-ha.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: prometheus-stress-test
  namespace: observability
spec:
  template:
    spec:
      containers:
      - name: stress
        image: progrium/stress
        args:
          - '--cpu'
          - '2'
          - '--io'
          - '1'
          - '--vm'
          - '2'
          - '--vm-bytes'
          - '128M'
          - '--timeout'
          - '60s'
        resources:
          requests:
            cpu: "100m"
            memory: "50Mi"
      - name: monitor
        image: curlimages/curl:latest
        command:
        - /bin/sh
        - -c
        - |
          echo "Monitoring pendant le stress test..."
          for i in $(seq 1 12); do
            echo "Check $i/12:"
            curl -s http://prometheus-lb:9090/api/v1/query?query=up | grep -o '"status":"[^"]*"'
            sleep 5
          done
      restartPolicy: Never
```

## Int√©gration avec l'√©cosyst√®me cloud-native

### Prometheus Operator pour simplifier la HA

L'utilisation de Prometheus Operator simplifie grandement la gestion HA :

```yaml
# prometheus-operator-ha.yaml
apiVersion: monitoring.coreos.com/v1
kind: Prometheus
metadata:
  name: prometheus-ha
  namespace: observability
spec:
  replicas: 2  # Nombre de r√©pliques
  version: v2.45.0
  serviceAccountName: prometheus

  # Configuration HA native
  enableAdminAPI: true

  # Sharding automatique pour distribuer la charge
  shards: 2

  # Configuration de la r√©tention
  retention: 30d
  retentionSize: "10GB"

  # Ressources par r√©plique
  resources:
    requests:
      memory: 1Gi
      cpu: 500m
    limits:
      memory: 2Gi
      cpu: 1000m

  # Stockage persistant
  storage:
    volumeClaimTemplate:
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 20Gi

  # Anti-affinit√© pour distribution sur diff√©rents n≈ìuds
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: prometheus
            operator: In
            values:
            - prometheus-ha
        topologyKey: kubernetes.io/hostname

  # Configuration des ServiceMonitors √† scraper
  serviceMonitorSelector:
    matchLabels:
      monitoring: "true"

  # Configuration Alertmanager
  alerting:
    alertmanagers:
    - namespace: observability
      name: alertmanager-ha
      port: web
```

### Int√©gration avec Service Mesh (Istio/Linkerd)

Pour une observabilit√© avanc√©e avec un service mesh :

```yaml
# istio-prometheus-ha.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-istio-config
  namespace: observability
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      external_labels:
        mesh: istio
        replica: $(POD_NAME)

    scrape_configs:
    # M√©triques Istio Telemetry v2
    - job_name: 'istio-mesh'
      kubernetes_sd_configs:
      - role: endpoints
        namespaces:
          names:
          - istio-system
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_name]
        action: keep
        regex: istio-telemetry
      - source_labels: [__meta_kubernetes_endpoint_port_name]
        action: keep
        regex: prometheus

    # M√©triques des sidecars Envoy
    - job_name: 'envoy-stats'
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_container_port_name]
        action: keep
        regex: '.*-envoy-prom'
      - source_labels: [__meta_kubernetes_pod_label_app]
        target_label: app
      - source_labels: [__meta_kubernetes_namespace]
        target_label: namespace

    # M√©triques du control plane Istio
    - job_name: 'istio-control-plane'
      kubernetes_sd_configs:
      - role: endpoints
        namespaces:
          names:
          - istio-system
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_label_app]
        regex: istiod
        action: keep
```

## Optimisations sp√©cifiques pour MicroK8s

### Configuration pour Raspberry Pi ou hardware limit√©

Si votre lab tourne sur des Raspberry Pi ou du hardware limit√© :

```yaml
# prometheus-ha-rpi.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-rpi-config
  namespace: observability
data:
  prometheus.yml: |
    global:
      scrape_interval: 60s  # Intervalle plus long
      scrape_timeout: 10s
      evaluation_interval: 60s

      # Labels externes pour identifier le hardware
      external_labels:
        hardware: rpi
        replica: $(HOSTNAME)

    # Optimisations pour ARM
    storage:
      tsdb:
        wal_compression: true
        max_block_duration: 2h
        min_block_duration: 2h
        retention.time: 3d  # R√©tention courte
        retention.size: 2GB  # Limite stricte
---
apiVersion: apps/v1
kind: DaemonSet  # Un Prometheus par n≈ìud RPi
metadata:
  name: prometheus-ha-rpi
  namespace: observability
spec:
  selector:
    matchLabels:
      app: prometheus-rpi
  template:
    metadata:
      labels:
        app: prometheus-rpi
    spec:
      nodeSelector:
        kubernetes.io/arch: arm64  # ou armhf selon votre architecture
      containers:
      - name: prometheus
        image: prom/prometheus:v2.45.0-arm64  # Image ARM
        resources:
          limits:
            memory: 512Mi  # Limite stricte pour RPi
            cpu: 1000m
          requests:
            memory: 256Mi
            cpu: 100m
        args:
          - '--config.file=/etc/prometheus/prometheus.yml'
          - '--storage.tsdb.path=/prometheus'
          - '--storage.tsdb.retention.time=3d'
          - '--storage.tsdb.retention.size=2GB'
          - '--storage.tsdb.wal-compression'
          - '--query.max-concurrency=2'  # Limite les requ√™tes parall√®les
          - '--query.max-samples=50000'  # Limite les √©chantillons par requ√™te
```

### Utilisation des addons MicroK8s

Int√©gration avec les addons MicroK8s pour la HA :

```bash
# Script d'installation HA avec addons MicroK8s
#!/bin/bash

echo "Configuration Prometheus HA pour MicroK8s"

# Activation des addons n√©cessaires
microk8s enable dns storage metallb:192.168.1.100-192.168.1.110

# Attente que les addons soient pr√™ts
microk8s kubectl wait --for=condition=available --timeout=600s \
  deployment/coredns -n kube-system

# Cr√©ation du namespace
microk8s kubectl create namespace observability

# Installation de Prometheus avec HA
cat <<EOF | microk8s kubectl apply -f -
apiVersion: v1
kind: Service
metadata:
  name: prometheus-ha-lb
  namespace: observability
  annotations:
    metallb.universe.tf/loadBalancerIPs: 192.168.1.100
spec:
  type: LoadBalancer
  ports:
  - port: 9090
    targetPort: 9090
    protocol: TCP
    name: http
  selector:
    app: prometheus-ha
EOF

echo "Configuration HA termin√©e"
echo "Acc√®s Prometheus HA: http://192.168.1.100:9090"
```

## Conclusion finale

La haute disponibilit√© de Prometheus dans un environnement MicroK8s repr√©sente un excellent terrain d'apprentissage pour ma√Ætriser les concepts de r√©silience et de fiabilit√© des syst√®mes de monitoring. En commen√ßant par des configurations simples et en √©voluant progressivement vers des architectures plus complexes, vous d√©veloppez des comp√©tences pr√©cieuses tout en maintenant un syst√®me de monitoring robuste pour votre lab.

Les points cl√©s √† retenir :

1. **Commencez simple** : Deux instances Prometheus avec un load balancer suffisent pour d√©buter
2. **√âvoluez progressivement** : Ajoutez des fonctionnalit√©s HA au fur et √† mesure de vos besoins
3. **Testez r√©guli√®rement** : Les tests de r√©silience sont essentiels pour valider votre configuration
4. **Adaptez aux ressources** : Optimisez pour votre hardware sp√©cifique
5. **Documentez tout** : Vos configurations, proc√©dures et apprentissages

La haute disponibilit√© n'est pas qu'une question technique, c'est aussi une approche m√©thodologique qui vous pr√©pare √† g√©rer des syst√®mes critiques en production. Votre lab MicroK8s est le terrain de jeu id√©al pour exp√©rimenter, √©chouer, apprendre et ma√Ætriser ces concepts sans risque.

‚è≠Ô∏è
