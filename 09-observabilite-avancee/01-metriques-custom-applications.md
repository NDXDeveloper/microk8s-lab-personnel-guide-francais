üîù Retour au [Sommaire](/SOMMAIRE.md)

# 9.1 M√©triques custom dans vos applications

## Introduction aux m√©triques personnalis√©es

Les m√©triques par d√©faut de Kubernetes (CPU, m√©moire, r√©seau) vous donnent une vue de l'infrastructure, mais elles ne racontent qu'une partie de l'histoire. Pour vraiment comprendre si votre application fonctionne correctement, vous avez besoin de m√©triques sp√©cifiques √† votre logique m√©tier. Ces m√©triques custom sont la fen√™tre sur ce qui compte vraiment pour votre application.

Imaginez que vous d√©veloppez une boutique en ligne dans votre lab MicroK8s. Les m√©triques syst√®me vous diront si les pods consomment trop de CPU, mais elles ne vous diront pas combien de paniers sont abandonn√©s, quel est le temps moyen de traitement d'une commande, ou combien d'erreurs de paiement se produisent. Ce sont ces m√©triques m√©tier qui transforment des donn√©es techniques en insights actionnables.

## Comprendre le format Prometheus

Avant de cr√©er nos propres m√©triques, il est essentiel de comprendre comment Prometheus les consomme. Prometheus utilise un format texte simple et lisible par l'humain pour exposer les m√©triques.

### Structure d'une m√©trique Prometheus

Une m√©trique Prometheus suit cette structure basique :
```
nom_de_la_metrique{label1="valeur1",label2="valeur2"} valeur timestamp
```

Le nom identifie ce que vous mesurez. Les labels permettent de filtrer et agr√©ger les donn√©es. La valeur est le nombre mesur√©. Le timestamp est optionnel (Prometheus l'ajoute lors du scraping).

### Exemple concret
```
http_requests_total{method="GET",endpoint="/api/users",status="200"} 1547
```
Cette ligne indique que l'endpoint `/api/users` a re√ßu 1547 requ√™tes GET r√©ussies.

## Les quatre types de m√©triques Prometheus

Prometheus d√©finit quatre types de m√©triques, chacun adapt√© √† des cas d'usage sp√©cifiques. Comprendre quand utiliser chaque type est crucial pour une observabilit√© efficace.

### Counter : le compteur qui ne descend jamais

Un Counter est une m√©trique cumulative qui ne peut qu'augmenter ou √™tre remise √† z√©ro. C'est parfait pour compter des √©v√©nements : nombre de requ√™tes, erreurs, t√¢ches compl√©t√©es.

**Cas d'usage typiques :**
- Nombre total de requ√™tes HTTP re√ßues
- Nombre d'erreurs rencontr√©es
- Nombre de messages trait√©s dans une queue
- Nombre de connexions √† la base de donn√©es

**Convention de nommage :** Les counters se terminent g√©n√©ralement par `_total`.

**Exemple d'impl√©mentation conceptuelle :**
```python
# Pseudo-code pour illustrer le concept
requests_total = Counter('http_requests_total', 'Total HTTP requests')
errors_total = Counter('application_errors_total', 'Total application errors')

# Dans votre code applicatif
def handle_request():
    requests_total.increment()
    try:
        # Traitement de la requ√™te
        process_request()
    except Exception:
        errors_total.increment()
```

### Gauge : la jauge qui monte et descend

Un Gauge repr√©sente une valeur qui peut augmenter ou diminuer. C'est id√©al pour mesurer l'√©tat actuel de quelque chose.

**Cas d'usage typiques :**
- Nombre de connexions actives
- Temp√©rature d'un capteur
- Nombre d'√©l√©ments dans une queue
- Utilisation m√©moire custom
- Nombre de t√¢ches en cours

**Exemple d'impl√©mentation conceptuelle :**
```python
# Pseudo-code
active_connections = Gauge('websocket_connections_active', 'Active WebSocket connections')
queue_size = Gauge('task_queue_size', 'Number of tasks in queue')

# Dans votre code
def on_connection_open():
    active_connections.increment()

def on_connection_close():
    active_connections.decrement()
```

### Histogram : la distribution statistique

Un Histogram √©chantillonne les observations et les compte dans des buckets configurables. Il calcule automatiquement la somme et le nombre d'observations, permettant de calculer des moyennes et des percentiles.

**Cas d'usage typiques :**
- Temps de r√©ponse des requ√™tes
- Taille des r√©ponses HTTP
- Dur√©e des op√©rations de base de donn√©es
- Temps d'attente dans une queue

**Structure d'un histogram :**
Un histogram g√©n√®re plusieurs s√©ries temporelles :
- `_bucket{le="x"}` : nombre d'observations ‚â§ x
- `_sum` : somme de toutes les observations
- `_count` : nombre total d'observations

**Exemple d'impl√©mentation conceptuelle :**
```python
# Pseudo-code
request_duration = Histogram(
    'http_request_duration_seconds',
    'HTTP request latency',
    buckets=[0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0]
)

# Dans votre code
def handle_request():
    start_time = time.now()
    process_request()
    duration = time.now() - start_time
    request_duration.observe(duration)
```

### Summary : les percentiles pr√©cis

Un Summary est similaire √† un Histogram mais calcule les quantiles directement c√¥t√© client. Il est plus pr√©cis pour les percentiles mais plus co√ªteux en ressources.

**Cas d'usage typiques :**
- Quand vous avez besoin de percentiles pr√©cis
- Quand vous ne connaissez pas la distribution √† l'avance
- Pour des m√©triques critiques n√©cessitant une grande pr√©cision

**Diff√©rence avec Histogram :**
- Summary : calcul exact des percentiles c√¥t√© application
- Histogram : approximation des percentiles c√¥t√© Prometheus

## Instrumentation de vos applications

L'instrumentation est l'art d'ajouter des m√©triques √† votre code. Il existe plusieurs approches, de la plus manuelle √† la plus automatique.

### Biblioth√®ques client Prometheus

Prometheus fournit des biblioth√®ques officielles pour les langages populaires. Chaque biblioth√®que offre une API similaire pour cr√©er et exposer des m√©triques.

**Langages support√©s officiellement :**
- Go : la biblioth√®que de r√©f√©rence
- Java/Scala : avec support Spring Boot
- Python : int√©gration Flask/Django disponible
- Ruby : compatible avec Rails
- Node.js : pour applications JavaScript

### Pattern d'exposition des m√©triques

Toutes les applications suivent le m√™me pattern pour exposer leurs m√©triques :

1. **Cr√©er un endpoint HTTP** (g√©n√©ralement `/metrics`)
2. **Enregistrer les m√©triques** lors de l'initialisation
3. **Mettre √† jour les m√©triques** dans votre logique m√©tier
4. **Exposer les m√©triques** au format Prometheus

### Exemple Python avec Flask

Voici un exemple complet mais simple d'une application Flask instrument√©e :

```python
from flask import Flask, Response
from prometheus_client import Counter, Histogram, Gauge, generate_latest
import time
import random

app = Flask(__name__)

# D√©finition des m√©triques
request_count = Counter(
    'app_requests_total',
    'Total number of requests',
    ['method', 'endpoint', 'status']
)

request_duration = Histogram(
    'app_request_duration_seconds',
    'Request duration',
    ['method', 'endpoint']
)

active_users = Gauge(
    'app_active_users',
    'Number of active users'
)

# Decorator pour mesurer automatiquement les requ√™tes
def track_metrics(f):
    def wrapper(*args, **kwargs):
        start = time.time()
        status = "500"
        try:
            result = f(*args, **kwargs)
            status = "200"
            return result
        except Exception as e:
            status = "500"
            raise e
        finally:
            duration = time.time() - start
            request_count.labels(
                method='GET',
                endpoint=f.__name__,
                status=status
            ).inc()
            request_duration.labels(
                method='GET',
                endpoint=f.__name__
            ).observe(duration)

    wrapper.__name__ = f.__name__
    return wrapper

@app.route('/')
@track_metrics
def home():
    # Simuler du travail
    time.sleep(random.uniform(0.1, 0.5))
    return "Hello from instrumented app!"

@app.route('/users')
@track_metrics
def users():
    # Simuler des utilisateurs actifs
    active_users.set(random.randint(10, 100))
    time.sleep(random.uniform(0.2, 0.8))
    return "Users endpoint"

@app.route('/metrics')
def metrics():
    # Endpoint pour Prometheus
    return Response(generate_latest(), mimetype='text/plain')

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

### Exemple Node.js avec Express

Pour les d√©veloppeurs JavaScript, voici l'√©quivalent en Node.js :

```javascript
const express = require('express');
const promClient = require('prom-client');

const app = express();
const register = new promClient.Registry();

// M√©triques par d√©faut (CPU, m√©moire, etc.)
promClient.collectDefaultMetrics({ register });

// M√©triques custom
const httpRequestsTotal = new promClient.Counter({
  name: 'http_requests_total',
  help: 'Total number of HTTP requests',
  labelNames: ['method', 'route', 'status'],
  registers: [register]
});

const httpDuration = new promClient.Histogram({
  name: 'http_request_duration_ms',
  help: 'Duration of HTTP requests in ms',
  labelNames: ['method', 'route'],
  buckets: [0.1, 5, 15, 50, 100, 500],
  registers: [register]
});

const connectedUsers = new promClient.Gauge({
  name: 'connected_users',
  help: 'Number of connected users',
  registers: [register]
});

// Middleware pour tracker toutes les requ√™tes
app.use((req, res, next) => {
  const start = Date.now();

  res.on('finish', () => {
    const duration = Date.now() - start;
    httpRequestsTotal.labels(req.method, req.route?.path || req.path, res.statusCode).inc();
    httpDuration.labels(req.method, req.route?.path || req.path).observe(duration);
  });

  next();
});

// Routes application
app.get('/', (req, res) => {
  res.send('Hello from Node.js instrumented app!');
});

app.get('/users', (req, res) => {
  // Simuler des utilisateurs connect√©s
  connectedUsers.set(Math.floor(Math.random() * 50) + 10);
  res.json({ users: 'data' });
});

// Endpoint pour Prometheus
app.get('/metrics', async (req, res) => {
  res.set('Content-Type', register.contentType);
  res.end(await register.metrics());
});

app.listen(3000, () => {
  console.log('Server running on port 3000');
});
```

## D√©ploiement sur MicroK8s

Une fois votre application instrument√©e, il faut la d√©ployer sur MicroK8s et configurer Prometheus pour collecter les m√©triques.

### Manifeste Kubernetes pour l'application

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: instrumented-app
  namespace: default
spec:
  replicas: 3
  selector:
    matchLabels:
      app: instrumented-app
  template:
    metadata:
      labels:
        app: instrumented-app
      annotations:
        # Annotations pour que Prometheus d√©couvre automatiquement l'app
        prometheus.io/scrape: "true"
        prometheus.io/port: "5000"
        prometheus.io/path: "/metrics"
    spec:
      containers:
      - name: app
        image: your-registry/instrumented-app:latest
        ports:
        - containerPort: 5000
          name: http
        - containerPort: 5000
          name: metrics
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "500m"
---
apiVersion: v1
kind: Service
metadata:
  name: instrumented-app
  labels:
    app: instrumented-app
spec:
  selector:
    app: instrumented-app
  ports:
  - name: http
    port: 80
    targetPort: 5000
  - name: metrics
    port: 5000
    targetPort: 5000
```

### Configuration du ServiceMonitor

Pour que Prometheus d√©couvre automatiquement votre application, cr√©ez un ServiceMonitor :

```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: instrumented-app
  namespace: default
spec:
  selector:
    matchLabels:
      app: instrumented-app
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
```

## Bonnes pratiques pour les m√©triques custom

### Nommage des m√©triques

Suivez ces conventions pour des m√©triques claires et coh√©rentes :

1. **Utilisez des underscores** pour s√©parer les mots : `http_requests_total`
2. **Incluez l'unit√©** dans le nom : `_seconds`, `_bytes`, `_total`
3. **Soyez descriptif** mais concis : `database_connection_pool_size`
4. **Groupez par pr√©fixe** : `myapp_feature_metric`

### Labels : puissance et dangers

Les labels permettent de filtrer et agr√©ger vos m√©triques, mais attention √† la cardinalit√© !

**Bonnes pratiques pour les labels :**
- Utilisez des labels pour les dimensions importantes (method, endpoint, status)
- √âvitez les valeurs uniques (user_id, session_id)
- Limitez le nombre de valeurs possibles par label
- Pr√©f√©rez des labels g√©n√©riques (status="4xx") aux sp√©cifiques (status="404")

**Exemple de mauvaise pratique :**
```
# √âVITEZ : cardinalit√© explosive
http_requests_total{user_id="12345", session_id="abc-def-ghi", timestamp="2024-01-01-10:23:45"}

# PR√âF√âREZ : cardinalit√© contr√¥l√©e
http_requests_total{method="GET", endpoint="/api/users", status="2xx"}
```

### Fr√©quence de mise √† jour

Diff√©rentes m√©triques n√©cessitent diff√©rentes fr√©quences de mise √† jour :

- **Counters** : mettez √† jour √† chaque √©v√©nement
- **Gauges** : mettez √† jour quand la valeur change ou p√©riodiquement
- **Histograms/Summaries** : observez chaque occurrence

### Gestion de la performance

L'instrumentation a un co√ªt. Voici comment le minimiser :

1. **√âvitez les calculs complexes** dans le hot path
2. **Utilisez l'√©chantillonnage** pour les m√©triques haute fr√©quence
3. **Agr√©gez c√¥t√© application** quand possible
4. **Limitez la cardinalit√©** des labels

## M√©triques m√©tier vs m√©triques techniques

### M√©triques techniques

Ces m√©triques concernent le fonctionnement technique de votre application :
- Latence des requ√™tes
- Taux d'erreur
- Utilisation du pool de connexions
- Taille des queues internes
- Performance du garbage collector

### M√©triques m√©tier

Ces m√©triques refl√®tent la valeur business de votre application :
- Nombre de commandes pass√©es
- Valeur moyenne du panier
- Taux de conversion
- Nombre d'utilisateurs actifs
- Revenue par minute

### Exemple complet : E-commerce

Voici comment instrumenter une application e-commerce avec les deux types :

```python
# M√©triques techniques
request_latency = Histogram('http_request_duration_seconds', 'Request latency')
db_connections = Gauge('database_connections_active', 'Active DB connections')
cache_hits = Counter('cache_hits_total', 'Cache hits')
cache_misses = Counter('cache_misses_total', 'Cache misses')

# M√©triques m√©tier
orders_created = Counter('shop_orders_created_total', 'Orders created')
order_value = Histogram('shop_order_value_euros', 'Order value in euros',
                       buckets=[10, 25, 50, 100, 250, 500, 1000])
cart_abandonment = Counter('shop_carts_abandoned_total', 'Abandoned carts')
payment_failures = Counter('shop_payment_failures_total', 'Payment failures',
                         ['reason'])
active_shopping_sessions = Gauge('shop_active_sessions', 'Active shopping sessions')
```

## RED Method et USE Method

Deux m√©thodologies populaires guident le choix des m√©triques √† impl√©menter.

### RED Method (pour les services)

RED signifie Rate, Errors, Duration. Pour chaque service, mesurez :

- **Rate** : nombre de requ√™tes par seconde
- **Errors** : nombre de requ√™tes √©chou√©es
- **Duration** : temps de traitement des requ√™tes

```python
# Impl√©mentation RED
rate = Counter('service_requests_total', 'Request rate')
errors = Counter('service_errors_total', 'Error rate')
duration = Histogram('service_duration_seconds', 'Request duration')
```

### USE Method (pour les ressources)

USE signifie Utilization, Saturation, Errors. Pour chaque ressource, mesurez :

- **Utilization** : pourcentage de temps occup√©
- **Saturation** : quantit√© de travail en attente
- **Errors** : nombre d'erreurs

```python
# Impl√©mentation USE pour un pool de workers
utilization = Gauge('worker_pool_utilization_ratio', 'Pool utilization')
saturation = Gauge('worker_pool_queue_length', 'Tasks waiting')
errors = Counter('worker_pool_errors_total', 'Processing errors')
```

## Int√©gration avec les dashboards Grafana

Une fois vos m√©triques custom expos√©es, cr√©ez des dashboards Grafana pertinents.

### Requ√™tes PromQL pour m√©triques custom

Quelques exemples de requ√™tes utiles :

```promql
# Taux de requ√™tes par seconde
rate(app_requests_total[5m])

# Latence p95
histogram_quantile(0.95, rate(app_request_duration_seconds_bucket[5m]))

# Taux d'erreur en pourcentage
100 * sum(rate(app_requests_total{status=~"5.."}[5m]))
    / sum(rate(app_requests_total[5m]))

# √âvolution du nombre d'utilisateurs actifs
app_active_users

# Top 5 des endpoints les plus lents
topk(5, histogram_quantile(0.99, rate(app_request_duration_seconds_bucket[5m])))
```

### Organisation des dashboards

Structurez vos dashboards par niveau d'abstraction :

1. **Vue d'ensemble** : m√©triques business critiques
2. **Sant√© des services** : RED metrics pour chaque service
3. **D√©tails techniques** : m√©triques d'infrastructure et de performance
4. **Debugging** : m√©triques d√©taill√©es pour investigation

## Debugging avec les m√©triques custom

Les m√©triques custom sont particuli√®rement utiles pour le debugging en production.

### M√©triques de debug temporaires

Parfois, vous avez besoin de m√©triques suppl√©mentaires pour investiguer un probl√®me :

```python
# Feature flag pour activer les m√©triques de debug
if DEBUG_METRICS_ENABLED:
    detailed_processing = Histogram(
        'debug_processing_steps_duration',
        'Detailed processing time',
        ['step']
    )

    # Dans le code
    with timer(detailed_processing.labels(step='validation')):
        validate_data()
    with timer(detailed_processing.labels(step='transformation')):
        transform_data()
```

### Correlation avec les logs

Enrichissez vos logs avec les valeurs de m√©triques pour faciliter la corr√©lation :

```python
logger.info("Request processed", extra={
    'duration': duration,
    'endpoint': endpoint,
    'active_connections': active_connections.get(),
    'queue_size': queue_size.get()
})
```

## Alerting sur m√©triques custom

D√©finissez des alertes Prometheus bas√©es sur vos m√©triques m√©tier :

```yaml
groups:
- name: business_alerts
  rules:
  - alert: HighCartAbandonment
    expr: rate(shop_carts_abandoned_total[1h]) > 10
    for: 5m
    annotations:
      summary: "High cart abandonment rate"
      description: "{{ $value }} carts/hour abandoned"

  - alert: PaymentSystemFailure
    expr: rate(shop_payment_failures_total[5m]) > 0.1
    for: 2m
    annotations:
      summary: "Payment system experiencing failures"
      description: "{{ $value }} failures per second"
```

## Migration vers OpenTelemetry

OpenTelemetry est le futur de l'instrumentation. Voici comment pr√©parer la migration :

### Approche hybride

Commencez par utiliser OpenTelemetry pour les nouvelles applications tout en gardant Prometheus pour l'existant :

```python
from opentelemetry import metrics
from opentelemetry.exporter.prometheus import PrometheusMetricReader

# Configuration OpenTelemetry avec export Prometheus
meter = metrics.get_meter(__name__)

# Cr√©ation de m√©triques OpenTelemetry
request_counter = meter.create_counter(
    "requests",
    description="Number of requests",
    unit="1"
)

# Utilisation identique
request_counter.add(1, {"method": "GET", "endpoint": "/api"})
```

### Avantages d'OpenTelemetry

- **Unified SDK** : m√™me API pour m√©triques, traces et logs
- **Auto-instrumentation** : support automatique des frameworks populaires
- **Vendor-agnostic** : changez de backend sans modifier le code
- **Context propagation** : correlation automatique entre signaux

## Conclusion et prochaines √©tapes

Les m√©triques custom transforment votre capacit√© √† comprendre et optimiser vos applications. Dans votre lab MicroK8s, elles vous permettent d'exp√©rimenter avec l'observabilit√© professionnelle sans les contraintes de la production.

Commencez simple avec quelques m√©triques RED/USE, puis enrichissez progressivement avec des m√©triques m√©tier sp√©cifiques. Rappelez-vous que chaque m√©trique a un co√ªt : choisissez celles qui apportent vraiment de la valeur.

Dans la prochaine section, nous explorerons la centralisation des logs, le deuxi√®me pilier de l'observabilit√©, qui compl√®tera parfaitement vos m√©triques custom en fournissant le contexte d√©taill√© derri√®re les chiffres.

‚è≠Ô∏è
