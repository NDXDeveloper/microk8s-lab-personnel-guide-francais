üîù Retour au [Sommaire](/SOMMAIRE.md)

# 13.1 Horizontal Pod Autoscaler (HPA)

## Qu'est-ce que l'Horizontal Pod Autoscaler ?

L'Horizontal Pod Autoscaler (HPA) est un contr√¥leur Kubernetes qui ajuste automatiquement le nombre de r√©pliques d'un d√©ploiement, ReplicaSet ou StatefulSet en fonction de m√©triques observ√©es. Imaginez un restaurant qui ouvre plus de caisses quand la file d'attente s'allonge, puis les ferme quand le rush est pass√©. HPA fait exactement cela pour vos applications : il ajoute des pods quand la charge augmente et les retire quand elle diminue.

Dans un environnement MicroK8s de lab, HPA vous permet d'optimiser l'utilisation de vos ressources limit√©es en n'allouant que ce qui est n√©cessaire √† chaque instant, tout en maintenant la performance de vos applications.

## Comment Fonctionne HPA ?

Le fonctionnement de HPA suit un cycle continu de surveillance et d'ajustement :

**Phase d'observation** : Toutes les 15 secondes par d√©faut, HPA interroge les m√©triques server pour obtenir les valeurs actuelles des m√©triques surveill√©es (CPU, m√©moire, ou m√©triques custom).

**Phase de calcul** : HPA calcule le nombre de r√©pliques n√©cessaire en utilisant la formule :
```
R√©pliques d√©sir√©es = ceil(somme(m√©trique actuelle) / valeur cible)
```

**Phase de d√©cision** : Si le nombre calcul√© diff√®re du nombre actuel de r√©pliques et que le cooldown period est respect√© (3 minutes pour scale up, 5 minutes pour scale down par d√©faut), HPA d√©cide d'ajuster.

**Phase d'action** : HPA modifie le champ `replicas` de la ressource cible, d√©clenchant la cr√©ation ou suppression de pods par le ReplicaSet controller.

## Pr√©requis pour Utiliser HPA

Avant de configurer HPA dans votre cluster MicroK8s, plusieurs √©l√©ments doivent √™tre en place :

### Metrics Server

Le metrics server est indispensable pour HPA. Il collecte les m√©triques de ressources des nodes et pods. Pour l'activer dans MicroK8s :

```bash
microk8s enable metrics-server
```

V√©rifiez que le metrics server fonctionne :
```bash
kubectl top nodes
kubectl top pods --all-namespaces
```

### Ressources Requests

Les pods que vous souhaitez autoscaler doivent d√©finir des resource requests. Sans requests CPU, HPA ne peut pas calculer le pourcentage d'utilisation. Voici pourquoi c'est crucial :

```yaml
resources:
  requests:
    cpu: 100m      # Le pod demande 100 millicores
    memory: 128Mi  # Le pod demande 128 MiB de RAM
  limits:
    cpu: 500m      # Maximum 500 millicores
    memory: 512Mi  # Maximum 512 MiB
```

Sans ces requests, HPA ne sait pas si un pod utilisant 50m de CPU est √† 50% ou √† 5% de sa capacit√© cible.

## Configuration Basique de HPA

### M√©thode 1 : Via kubectl (Approche Simple)

La fa√ßon la plus rapide de cr√©er un HPA est d'utiliser la commande kubectl :

```bash
kubectl autoscale deployment mon-app --cpu-percent=50 --min=1 --max=10
```

Cette commande cr√©e un HPA qui :
- Surveille le deployment "mon-app"
- Maintient l'utilisation CPU moyenne √† 50%
- Garde entre 1 et 10 r√©pliques

### M√©thode 2 : Via Manifeste YAML (Approche D√©clarative)

Pour plus de contr√¥le et de reproductibilit√©, utilisez un manifeste YAML :

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: mon-app-hpa
  namespace: default
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: mon-app
  minReplicas: 1
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

Ce manifeste configure un HPA plus sophistiqu√© qui surveille √† la fois CPU et m√©moire.

## Types de M√©triques Support√©es

HPA peut utiliser diff√©rents types de m√©triques pour prendre ses d√©cisions :

### M√©triques de Ressources

Les plus communes et simples √† impl√©menter :

```yaml
metrics:
- type: Resource
  resource:
    name: cpu
    target:
      type: Utilization        # Pourcentage des requests
      averageUtilization: 70
- type: Resource
  resource:
    name: memory
    target:
      type: AverageValue       # Valeur absolue
      averageValue: "500Mi"    # Scale si > 500Mi par pod
```

### M√©triques de Pods (Custom Metrics)

Pour des m√©triques expos√©es par les pods eux-m√™mes :

```yaml
metrics:
- type: Pods
  pods:
    metric:
      name: requests_per_second
    target:
      type: AverageValue
      averageValue: "1000"      # 1000 requ√™tes/seconde par pod
```

### M√©triques d'Objets

Bas√©es sur des m√©triques d'autres objets Kubernetes :

```yaml
metrics:
- type: Object
  object:
    metric:
      name: requests-per-second
    describedObject:
      apiVersion: networking.k8s.io/v1
      kind: Ingress
      name: main-route
    target:
      type: Value
      value: "10k"              # 10000 requ√™tes totales
```

### M√©triques Externes

Provenant de syst√®mes externes au cluster :

```yaml
metrics:
- type: External
  external:
    metric:
      name: queue_messages
      selector:
        matchLabels:
          queue: "worker-tasks"
    target:
      type: AverageValue
      averageValue: "100"       # 100 messages par pod
```

## Comportement et Param√®tres Avanc√©s

### Stabilisation et Cooldown

HPA inclut des m√©canismes pour √©viter le "flapping" (oscillation rapide) :

```yaml
spec:
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300  # Fen√™tre de 5 minutes
      policies:
      - type: Percent
        value: 50                      # Max 50% de pods en moins
        periodSeconds: 60              # Par minute
      - type: Pods
        value: 2                       # Max 2 pods en moins
        periodSeconds: 60              # Par minute
      selectPolicy: Min                # Politique la plus conservative
    scaleUp:
      stabilizationWindowSeconds: 60   # Fen√™tre de 1 minute
      policies:
      - type: Percent
        value: 100                     # Double au maximum
        periodSeconds: 60
      - type: Pods
        value: 4                       # Max 4 pods ajout√©s
        periodSeconds: 60
      selectPolicy: Max                # Politique la plus agressive
```

### Strat√©gies de Scaling

Vous pouvez d√©finir comment HPA s√©lectionne les m√©triques quand plusieurs sont configur√©es :

```yaml
spec:
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  # HPA utilisera la m√©trique qui demande le plus de r√©pliques
```

## Surveillance et Debugging de HPA

### V√©rifier le Status

Pour voir l'√©tat actuel de vos HPA :

```bash
# Liste tous les HPA
kubectl get hpa

# D√©tails d'un HPA sp√©cifique
kubectl describe hpa mon-app-hpa

# Observer en temps r√©el
kubectl get hpa mon-app-hpa --watch
```

### Interpr√©ter les Outputs

Un output typique de `kubectl get hpa` :
```
NAME          REFERENCE            TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
mon-app-hpa   Deployment/mon-app   45%/50%   1         10        4          10m
```

- **TARGETS** : Utilisation actuelle / cible
- **REPLICAS** : Nombre actuel de pods
- **45%/50%** : Utilisation CPU √† 45%, cible √† 50%

### Events et Logs

Pour comprendre les d√©cisions de HPA :

```bash
# Events du HPA
kubectl describe hpa mon-app-hpa | grep -A 10 Events

# Logs du metrics server
kubectl logs -n kube-system deployment/metrics-server

# Events du deployment scal√©
kubectl describe deployment mon-app | grep -A 10 Events
```

## Bonnes Pratiques pour HPA

### Dimensionnement des Requests

D√©finissez des requests r√©alistes bas√©es sur des observations :

```yaml
# Mauvais : requests trop basses
resources:
  requests:
    cpu: 10m     # HPA va sur-r√©agir

# Bon : requests bas√©es sur l'utilisation r√©elle
resources:
  requests:
    cpu: 100m    # Proche de l'utilisation normale
```

### Choix des Seuils

Les seuils d√©pendent de votre application :

- **Applications stateless** : 70-80% CPU est acceptable
- **Applications avec √©tat** : 50-60% pour garder de la marge
- **APIs critiques** : 40-50% pour garantir la r√©activit√©

### Limites Min/Max Appropri√©es

```yaml
# Pour un lab personnel
minReplicas: 1    # √âconomise les ressources au repos
maxReplicas: 5    # √âvite de saturer le cluster

# Pour une app critique
minReplicas: 2    # Haute disponibilit√©
maxReplicas: 10   # Peut g√©rer les pics importants
```

### Combinaison de M√©triques

Utilisez plusieurs m√©triques pour une d√©cision plus intelligente :

```yaml
metrics:
- type: Resource
  resource:
    name: cpu
    target:
      type: Utilization
      averageUtilization: 70
- type: Resource
  resource:
    name: memory
    target:
      type: Utilization
      averageUtilization: 85
```

## Cas d'Usage Typiques dans un Lab

### Application Web Simple

Pour une application web dans votre lab :

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: webapp-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: webapp
  minReplicas: 1
  maxReplicas: 3
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 60
```

### Worker de Traitement

Pour un worker qui traite des t√¢ches :

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: worker-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: worker
  minReplicas: 0    # Peut descendre √† z√©ro
  maxReplicas: 5
  metrics:
  - type: External
    external:
      metric:
        name: queue_length
      target:
        type: AverageValue
        averageValue: "10"  # 10 messages par worker
```

### API avec Patterns Pr√©visibles

Pour une API avec des pics connus :

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: api-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api
  minReplicas: 2
  maxReplicas: 8
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 30    # R√©action rapide
      policies:
      - type: Percent
        value: 200                      # Double rapidement
        periodSeconds: 30
```

## Limitations et Consid√©rations

### Limitations Techniques

HPA a certaines contraintes √† conna√Ætre :

- **D√©lai de r√©action** : Minimum 15 secondes entre les checks
- **Cooldown periods** : Emp√™che les ajustements trop fr√©quents
- **M√©triques manquantes** : Si metrics-server est down, HPA ne scale pas
- **Pods en d√©marrage** : Les m√©triques des pods qui d√©marrent sont ignor√©es

### Consid√©rations pour un Lab

Dans un environnement MicroK8s de lab :

- **Ressources limit√©es** : MaxReplicas doit tenir compte du total disponible
- **Co√ªt du scaling** : Chaque pod consomme de la m√©moire de base
- **Temps de d√©marrage** : Les images lourdes ralentissent le scaling
- **Stockage** : Les PVC peuvent limiter o√π les nouveaux pods peuvent s'ex√©cuter

### Interactions avec d'Autres Fonctionnalit√©s

HPA doit coexister avec :

- **VPA** : Ne pas utiliser les deux sur les m√™mes m√©triques
- **Cluster Autoscaler** : Coordonner les limites
- **Pod Disruption Budgets** : Peuvent ralentir le scale down
- **Resource Quotas** : Peuvent emp√™cher le scale up

## Troubleshooting Commun

### HPA ne Scale pas

V√©rifications √† effectuer :

```bash
# Metrics server fonctionne ?
kubectl top nodes

# Requests d√©finies ?
kubectl describe deployment mon-app | grep -A 5 Requests

# HPA voit les m√©triques ?
kubectl describe hpa mon-app-hpa | grep "Current CPU"

# Events d'erreur ?
kubectl get events --field-selector involvedObject.name=mon-app-hpa
```

### Scaling Trop Agressif

Si HPA scale trop rapidement :

- Augmentez stabilizationWindowSeconds
- R√©duisez les pourcentages dans les policies
- Augmentez les seuils de d√©clenchement
- V√©rifiez que les requests sont r√©alistes

### M√©triques Incoh√©rentes

Si les m√©triques semblent incorrectes :

```bash
# Comparer les m√©triques
kubectl top pods
kubectl get hpa

# V√©rifier le calcul
kubectl get hpa mon-app-hpa -o yaml | grep -A 10 currentMetrics
```

## Monitoring et Observabilit√©

Pour surveiller efficacement vos HPA dans Grafana, surveillez ces m√©triques cl√©s :

- `kube_horizontalpodautoscaler_status_current_replicas` : Nombre actuel de r√©pliques
- `kube_horizontalpodautoscaler_status_desired_replicas` : Nombre d√©sir√©
- `kube_horizontalpodautoscaler_spec_max_replicas` : Maximum configur√©
- `kube_horizontalpodautoscaler_spec_min_replicas` : Minimum configur√©

Un dashboard efficace devrait montrer l'√©volution du nombre de r√©pliques en corr√©lation avec les m√©triques surveill√©es (CPU, m√©moire, custom metrics) pour valider que HPA prend les bonnes d√©cisions.

## Conclusion

L'Horizontal Pod Autoscaler est un outil puissant pour maintenir les performances tout en optimisant l'utilisation des ressources. Dans un environnement MicroK8s de lab, il permet d'exp√©rimenter avec des strat√©gies de scaling sophistiqu√©es tout en g√©rant efficacement les ressources limit√©es. La cl√© du succ√®s avec HPA r√©side dans la compr√©hension de votre application, le choix de m√©triques pertinentes, et l'ajustement patient des param√®tres bas√© sur l'observation du comportement r√©el.

‚è≠Ô∏è
