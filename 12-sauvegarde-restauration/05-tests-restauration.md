ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 12.5 Tests de restauration

## Introduction aux tests de restauration

Un test de restauration est comme une simulation d'incendie : vous pratiquez la procÃ©dure avant qu'une vraie urgence ne survienne. Dans le contexte de MicroK8s, cela signifie vÃ©rifier rÃ©guliÃ¨rement que vos sauvegardes peuvent rÃ©ellement restaurer votre systÃ¨me. Une sauvegarde non testÃ©e est comme une assurance dont vous n'Ãªtes pas sÃ»r qu'elle fonctionne - elle vous donne une fausse sÃ©curitÃ©.

### Pourquoi tester la restauration ?

**La rÃ¨gle d'or :** "Une sauvegarde n'est valide que si elle a Ã©tÃ© restaurÃ©e avec succÃ¨s."

**Raisons critiques pour tester :**
- **DÃ©tection prÃ©coce des problÃ¨mes** : Les sauvegardes peuvent Ãªtre corrompues ou incomplÃ¨tes
- **Validation des procÃ©dures** : S'assurer que la documentation est Ã  jour et correcte
- **Formation de l'Ã©quipe** : Pratiquer rÃ©duit le stress lors d'une vraie crise
- **Mesure du temps de rÃ©cupÃ©ration** : Savoir combien de temps prend une restauration
- **VÃ©rification de la complÃ©tude** : S'assurer que toutes les donnÃ©es nÃ©cessaires sont sauvegardÃ©es
- **Test des dÃ©pendances** : Identifier les ressources manquantes ou les configurations oubliÃ©es

### Types de tests de restauration

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Types de Tests de Restauration           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—       â”‚
â”‚  â•‘   Test Partiel     â•‘    â•‘   Test Complet    â•‘       â”‚
â”‚  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£       â”‚
â”‚  â•‘ â€¢ Un namespace     â•‘    â•‘ â€¢ Cluster entier  â•‘       â”‚
â”‚  â•‘ â€¢ Une application  â•‘    â•‘ â€¢ Tous services   â•‘       â”‚
â”‚  â•‘ â€¢ DurÃ©e: Minutes   â•‘    â•‘ â€¢ DurÃ©e: Heures   â•‘       â”‚
â”‚  â•‘ â€¢ Risque: Faible   â•‘    â•‘ â€¢ Risque: Moyen   â•‘       â”‚
â”‚  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•       â”‚
â”‚                                                          â”‚
â”‚  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—       â”‚
â”‚  â•‘   Test IsolÃ©       â•‘    â•‘   Test en Prod    â•‘       â”‚
â”‚  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£       â”‚
â”‚  â•‘ â€¢ Env. de test     â•‘    â•‘ â€¢ Env. rÃ©el       â•‘       â”‚
â”‚  â•‘ â€¢ Sans impact      â•‘    â•‘ â€¢ Maintenance     â•‘       â”‚
â”‚  â•‘ â€¢ Validation       â•‘    â•‘ â€¢ Validation      â•‘       â”‚
â”‚  â•‘   technique        â•‘    â•‘   complÃ¨te        â•‘       â”‚
â”‚  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Environnement de test isolÃ©

### CrÃ©ation d'un environnement de test

```bash
#!/bin/bash
# setup-test-environment.sh

TEST_NAMESPACE="restore-test-$(date +%Y%m%d-%H%M%S)"
TEST_CLUSTER_CONTEXT="microk8s-test"

# CrÃ©er un namespace isolÃ© pour les tests
create_test_namespace() {
    echo "ğŸ”§ CrÃ©ation du namespace de test: $TEST_NAMESPACE"

    cat <<EOF | microk8s kubectl apply -f -
apiVersion: v1
kind: Namespace
metadata:
  name: $TEST_NAMESPACE
  labels:
    purpose: restore-test
    created: $(date +%Y-%m-%d)
    temporary: "true"
  annotations:
    description: "Namespace temporaire pour test de restauration"
---
apiVersion: v1
kind: ResourceQuota
metadata:
  name: test-quota
  namespace: $TEST_NAMESPACE
spec:
  hard:
    requests.cpu: "2"
    requests.memory: 4Gi
    limits.cpu: "4"
    limits.memory: 8Gi
    persistentvolumeclaims: "5"
EOF

    echo "âœ… Namespace de test crÃ©Ã© avec quotas de ressources"
}

# DÃ©ployer une application de test
deploy_test_application() {
    echo "ğŸ“¦ DÃ©ploiement de l'application de test..."

    cat <<EOF | microk8s kubectl apply -n $TEST_NAMESPACE -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: test-config
data:
  app.properties: |
    environment=test
    version=1.0
    timestamp=$(date -Iseconds)
---
apiVersion: v1
kind: Secret
metadata:
  name: test-secret
type: Opaque
data:
  username: $(echo -n "testuser" | base64)
  password: $(echo -n "testpass123" | base64)
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: test-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: test-app
  template:
    metadata:
      labels:
        app: test-app
    spec:
      containers:
      - name: nginx
        image: nginx:alpine
        ports:
        - containerPort: 80
        volumeMounts:
        - name: config
          mountPath: /etc/config
        - name: data
          mountPath: /usr/share/nginx/html
        env:
        - name: TEST_USER
          valueFrom:
            secretKeyRef:
              name: test-secret
              key: username
      volumes:
      - name: config
        configMap:
          name: test-config
      - name: data
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: test-service
spec:
  selector:
    app: test-app
  ports:
  - port: 80
    targetPort: 80
EOF

    # Attendre que les pods soient prÃªts
    echo "â³ Attente du dÃ©marrage des pods..."
    microk8s kubectl wait --for=condition=ready pod -l app=test-app -n $TEST_NAMESPACE --timeout=60s

    echo "âœ… Application de test dÃ©ployÃ©e"
}

# Injecter des donnÃ©es de test
inject_test_data() {
    echo "ğŸ’‰ Injection de donnÃ©es de test..."

    # CrÃ©er des donnÃ©es dans les pods
    for pod in $(microk8s kubectl get pods -n $TEST_NAMESPACE -l app=test-app -o jsonpath='{.items[*].metadata.name}'); do
        echo "  Injection dans pod: $pod"

        # CrÃ©er des fichiers de test
        microk8s kubectl exec -n $TEST_NAMESPACE $pod -- sh -c "
            echo '<h1>Test Data</h1>' > /usr/share/nginx/html/index.html
            echo 'Timestamp: $(date)' >> /usr/share/nginx/html/index.html
            echo 'Pod: $pod' >> /usr/share/nginx/html/index.html
            echo 'Test file content' > /usr/share/nginx/html/test.txt
        "
    done

    # CrÃ©er des objets Kubernetes supplÃ©mentaires
    microk8s kubectl create configmap test-data \
        --from-literal=key1=value1 \
        --from-literal=key2=value2 \
        -n $TEST_NAMESPACE

    echo "âœ… DonnÃ©es de test injectÃ©es"
}

# CrÃ©er un snapshot de l'Ã©tat actuel
create_test_snapshot() {
    echo "ğŸ“¸ CrÃ©ation d'un snapshot de l'Ã©tat de test..."

    local snapshot_dir="./test-snapshots/$(date +%Y%m%d-%H%M%S)"
    mkdir -p "$snapshot_dir"

    # Exporter l'Ã©tat complet
    microk8s kubectl get all,cm,secret,pvc -n $TEST_NAMESPACE -o yaml > "$snapshot_dir/namespace-state.yaml"

    # CrÃ©er un hash pour validation
    sha256sum "$snapshot_dir/namespace-state.yaml" > "$snapshot_dir/checksum.sha256"

    echo "âœ… Snapshot crÃ©Ã©: $snapshot_dir"
    echo "$snapshot_dir" > last-test-snapshot.txt
}

# Configuration complÃ¨te de l'environnement de test
setup_complete_test_env() {
    echo "ğŸš€ Configuration de l'environnement de test complet"
    echo "===================================================="

    create_test_namespace
    deploy_test_application
    inject_test_data
    create_test_snapshot

    echo ""
    echo "ğŸ“Š RÃ©sumÃ© de l'environnement de test:"
    echo "  Namespace: $TEST_NAMESPACE"
    echo "  Pods: $(microk8s kubectl get pods -n $TEST_NAMESPACE --no-headers | wc -l)"
    echo "  Services: $(microk8s kubectl get svc -n $TEST_NAMESPACE --no-headers | wc -l)"
    echo "  ConfigMaps: $(microk8s kubectl get cm -n $TEST_NAMESPACE --no-headers | wc -l)"
    echo "  Secrets: $(microk8s kubectl get secret -n $TEST_NAMESPACE --no-headers | wc -l)"
    echo ""
    echo "âœ… Environnement de test prÃªt pour les tests de restauration"
}

# Nettoyage de l'environnement de test
cleanup_test_env() {
    echo "ğŸ§¹ Nettoyage de l'environnement de test..."

    if [ -z "$1" ]; then
        echo "Usage: cleanup_test_env <namespace>"
        return 1
    fi

    microk8s kubectl delete namespace "$1" --wait=false
    echo "âœ… Namespace $1 marquÃ© pour suppression"
}

# ExÃ©cution
setup_complete_test_env
```

## Tests de restauration basiques

### Test de restauration simple

```bash
#!/bin/bash
# basic-restore-test.sh

# Configuration
BACKUP_TOOL=${BACKUP_TOOL:-velero}  # velero, scripts, ou manual
TEST_TYPE=${1:-partial}  # partial, full, ou disaster

# Couleurs pour l'output
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m'

# Fonction de logging
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

# Test de restauration partielle
test_partial_restore() {
    log "ğŸ”¬ Test de restauration partielle"

    # 1. CrÃ©er un namespace de test
    local test_ns="partial-restore-test"
    microk8s kubectl create namespace $test_ns

    # 2. DÃ©ployer une application simple
    cat <<EOF | microk8s kubectl apply -n $test_ns -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: test-deployment
spec:
  replicas: 1
  selector:
    matchLabels:
      app: test
  template:
    metadata:
      labels:
        app: test
    spec:
      containers:
      - name: nginx
        image: nginx:alpine
        ports:
        - containerPort: 80
EOF

    # 3. Attendre le dÃ©ploiement
    microk8s kubectl wait --for=condition=available deployment/test-deployment -n $test_ns --timeout=60s

    # 4. Faire un backup
    log "ğŸ“¸ CrÃ©ation du backup..."
    case $BACKUP_TOOL in
        velero)
            velero backup create test-backup-$(date +%s) --include-namespaces=$test_ns --wait
            ;;
        *)
            microk8s kubectl get all -n $test_ns -o yaml > /tmp/test-backup.yaml
            ;;
    esac

    # 5. Supprimer l'application
    log "ğŸ—‘ï¸ Suppression de l'application..."
    microk8s kubectl delete deployment test-deployment -n $test_ns

    # 6. VÃ©rifier la suppression
    if microk8s kubectl get deployment test-deployment -n $test_ns 2>/dev/null; then
        echo -e "${RED}âŒ Ã‰chec de la suppression${NC}"
        return 1
    fi

    # 7. Restaurer
    log "â™»ï¸ Restauration..."
    case $BACKUP_TOOL in
        velero)
            velero restore create test-restore-$(date +%s) --from-backup test-backup-* --wait
            ;;
        *)
            microk8s kubectl apply -f /tmp/test-backup.yaml
            ;;
    esac

    # 8. VÃ©rifier la restauration
    if microk8s kubectl wait --for=condition=available deployment/test-deployment -n $test_ns --timeout=60s 2>/dev/null; then
        echo -e "${GREEN}âœ… Restauration rÃ©ussie!${NC}"

        # Nettoyer
        microk8s kubectl delete namespace $test_ns --wait=false
        return 0
    else
        echo -e "${RED}âŒ Ã‰chec de la restauration${NC}"
        return 1
    fi
}

# Test de restauration complÃ¨te
test_full_restore() {
    log "ğŸ”¬ Test de restauration complÃ¨te"

    # 1. CrÃ©er plusieurs namespaces avec applications
    local namespaces=("app-frontend" "app-backend" "app-database")

    for ns in "${namespaces[@]}"; do
        log "ğŸ“¦ CrÃ©ation de $ns..."
        microk8s kubectl create namespace $ns

        # DÃ©ployer une application dans chaque namespace
        cat <<EOF | microk8s kubectl apply -n $ns -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ${ns}-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: $ns
  template:
    metadata:
      labels:
        app: $ns
    spec:
      containers:
      - name: app
        image: nginx:alpine
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: ${ns}-service
spec:
  selector:
    app: $ns
  ports:
  - port: 80
EOF
    done

    # 2. Attendre que tout soit prÃªt
    log "â³ Attente du dÃ©ploiement complet..."
    for ns in "${namespaces[@]}"; do
        microk8s kubectl wait --for=condition=available deployment/${ns}-deployment -n $ns --timeout=60s
    done

    # 3. CrÃ©er un backup complet
    log "ğŸ“¸ Backup complet..."
    local backup_name="full-backup-$(date +%Y%m%d-%H%M%S)"

    case $BACKUP_TOOL in
        velero)
            velero backup create $backup_name --wait
            ;;
        *)
            for ns in "${namespaces[@]}"; do
                microk8s kubectl get all -n $ns -o yaml >> /tmp/${backup_name}.yaml
                echo "---" >> /tmp/${backup_name}.yaml
            done
            ;;
    esac

    # 4. Simuler un dÃ©sastre
    log "ğŸ’¥ Simulation de dÃ©sastre..."
    for ns in "${namespaces[@]}"; do
        microk8s kubectl delete namespace $ns --wait=false
    done

    sleep 10  # Attendre la suppression

    # 5. Restaurer
    log "â™»ï¸ Restauration complÃ¨te..."
    case $BACKUP_TOOL in
        velero)
            velero restore create restore-$(date +%s) --from-backup $backup_name --wait
            ;;
        *)
            microk8s kubectl apply -f /tmp/${backup_name}.yaml
            ;;
    esac

    # 6. Validation
    log "ğŸ” Validation de la restauration..."
    local success=true

    for ns in "${namespaces[@]}"; do
        if ! microk8s kubectl get namespace $ns 2>/dev/null; then
            echo -e "${RED}âŒ Namespace $ns non restaurÃ©${NC}"
            success=false
        elif ! microk8s kubectl get deployment ${ns}-deployment -n $ns 2>/dev/null; then
            echo -e "${RED}âŒ Deployment dans $ns non restaurÃ©${NC}"
            success=false
        else
            echo -e "${GREEN}âœ“ $ns restaurÃ©${NC}"
        fi
    done

    # 7. Nettoyer
    for ns in "${namespaces[@]}"; do
        microk8s kubectl delete namespace $ns --wait=false
    done

    if [ "$success" = true ]; then
        echo -e "${GREEN}âœ… Test de restauration complÃ¨te rÃ©ussi!${NC}"
        return 0
    else
        echo -e "${RED}âŒ Test de restauration complÃ¨te Ã©chouÃ©${NC}"
        return 1
    fi
}

# Test de disaster recovery
test_disaster_recovery() {
    log "ğŸ”¬ Test de disaster recovery"

    # Ce test simule une perte totale et une restauration
    echo "âš ï¸  Ce test va simuler une perte totale de donnÃ©es"
    echo "Continuer? (y/N)"
    read -r response

    if [[ ! "$response" =~ ^[Yy]$ ]]; then
        echo "Test annulÃ©"
        return 0
    fi

    # ImplÃ©mentation du test DR...
    # (Code similaire mais avec des scÃ©narios plus complexes)
}

# Menu principal
main() {
    echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    echo "â•‘     TESTS DE RESTAURATION MICROK8S        â•‘"
    echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo ""
    echo "Outil de backup: $BACKUP_TOOL"
    echo ""

    case $TEST_TYPE in
        partial)
            test_partial_restore
            ;;
        full)
            test_full_restore
            ;;
        disaster)
            test_disaster_recovery
            ;;
        *)
            echo "Type de test non reconnu: $TEST_TYPE"
            echo "Options: partial, full, disaster"
            exit 1
            ;;
    esac
}

# ExÃ©cution
main
```

## Tests automatisÃ©s et programmÃ©s

### Configuration de tests automatiques

```bash
#!/bin/bash
# automated-restore-tests.sh

# Configuration
TEST_SCHEDULE=${TEST_SCHEDULE:-"weekly"}  # daily, weekly, monthly
NOTIFICATION_EMAIL=${NOTIFICATION_EMAIL:-"admin@example.com"}
SLACK_WEBHOOK=${SLACK_WEBHOOK:-""}
TEST_LOG_DIR="/var/log/restore-tests"

# CrÃ©er la structure de logs
mkdir -p "$TEST_LOG_DIR"

# Fonction pour envoyer des notifications
send_notification() {
    local status=$1
    local message=$2
    local details=$3

    # Email
    if [ -n "$NOTIFICATION_EMAIL" ]; then
        echo "$details" | mail -s "Test de restauration: $status - $message" "$NOTIFICATION_EMAIL"
    fi

    # Slack
    if [ -n "$SLACK_WEBHOOK" ]; then
        curl -X POST -H 'Content-type: application/json' \
            --data "{\"text\":\"Test de restauration: $status\\n$message\\n\`\`\`$details\`\`\`\"}" \
            "$SLACK_WEBHOOK"
    fi

    # Log local
    echo "[$(date -Iseconds)] $status: $message" >> "$TEST_LOG_DIR/notifications.log"
}

# Test automatisÃ© avec rapport
run_automated_test() {
    local test_name=$1
    local test_function=$2
    local start_time=$(date +%s)
    local log_file="$TEST_LOG_DIR/test-$(date +%Y%m%d-%H%M%S).log"

    echo "ğŸ¤– ExÃ©cution du test automatisÃ©: $test_name" | tee -a "$log_file"
    echo "DÃ©marrÃ© Ã : $(date)" | tee -a "$log_file"
    echo "==========================================" | tee -a "$log_file"

    # ExÃ©cuter le test avec capture des logs
    if $test_function >> "$log_file" 2>&1; then
        local status="SUCCESS"
        local emoji="âœ…"
    else
        local status="FAILURE"
        local emoji="âŒ"
    fi

    local end_time=$(date +%s)
    local duration=$((end_time - start_time))

    # GÃ©nÃ©rer le rapport
    local report=$(cat <<EOF
$emoji Test: $test_name
Status: $status
DurÃ©e: ${duration}s
Date: $(date)
Log: $log_file

DÃ©tails:
$(tail -20 "$log_file")
EOF
    )

    echo "$report" | tee -a "$log_file"

    # Envoyer les notifications
    send_notification "$status" "$test_name" "$report"

    # Retourner le status
    [ "$status" = "SUCCESS" ]
}

# Suite de tests programmÃ©s
run_test_suite() {
    echo "ğŸ”„ Lancement de la suite de tests de restauration"
    echo "=================================================="

    local suite_log="$TEST_LOG_DIR/suite-$(date +%Y%m%d-%H%M%S).log"
    local tests_passed=0
    local tests_failed=0

    # Liste des tests Ã  exÃ©cuter
    local tests=(
        "test_backup_validity:Validation des backups"
        "test_partial_restore:Restauration partielle"
        "test_full_restore:Restauration complÃ¨te"
        "test_data_integrity:IntÃ©gritÃ© des donnÃ©es"
        "test_performance_metrics:MÃ©triques de performance"
    )

    for test_spec in "${tests[@]}"; do
        IFS=':' read -r test_function test_description <<< "$test_spec"

        echo "" | tee -a "$suite_log"
        echo "â–¶ï¸ Test: $test_description" | tee -a "$suite_log"

        if run_automated_test "$test_description" "$test_function"; then
            ((tests_passed++))
            echo "âœ… RÃ©ussi" | tee -a "$suite_log"
        else
            ((tests_failed++))
            echo "âŒ Ã‰chouÃ©" | tee -a "$suite_log"
        fi
    done

    # Rapport final
    local suite_report=$(cat <<EOF

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘        RAPPORT DE SUITE DE TESTS       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Date: $(date)
Tests rÃ©ussis: $tests_passed
Tests Ã©chouÃ©s: $tests_failed
Taux de rÃ©ussite: $(echo "scale=2; $tests_passed * 100 / ($tests_passed + $tests_failed)" | bc)%

Log complet: $suite_log
EOF
    )

    echo "$suite_report" | tee -a "$suite_log"

    # Notification finale
    if [ $tests_failed -eq 0 ]; then
        send_notification "âœ… SUCCESS" "Tous les tests ont rÃ©ussi" "$suite_report"
    else
        send_notification "âš ï¸ WARNING" "$tests_failed tests ont Ã©chouÃ©" "$suite_report"
    fi
}

# Tests spÃ©cifiques
test_backup_validity() {
    echo "ğŸ” Test de validitÃ© des backups"

    # VÃ©rifier l'existence des backups
    case $BACKUP_TOOL in
        velero)
            local backup_count=$(velero backup get --output json | jq '.items | length')
            if [ "$backup_count" -eq 0 ]; then
                echo "âŒ Aucun backup trouvÃ©"
                return 1
            fi

            # VÃ©rifier l'Ã¢ge du dernier backup
            local latest_backup=$(velero backup get --output json | jq -r '.items[0].metadata.creationTimestamp')
            local backup_age=$(( ($(date +%s) - $(date -d "$latest_backup" +%s)) / 3600 ))

            if [ $backup_age -gt 24 ]; then
                echo "âš ï¸  Le dernier backup date de plus de 24h"
                return 1
            fi
            ;;
        *)
            # VÃ©rification pour d'autres outils
            if [ ! -d "/backup" ] || [ -z "$(ls -A /backup)" ]; then
                echo "âŒ RÃ©pertoire de backup vide"
                return 1
            fi
            ;;
    esac

    echo "âœ… Backups valides trouvÃ©s"
    return 0
}

test_data_integrity() {
    echo "ğŸ” Test d'intÃ©gritÃ© des donnÃ©es"

    # CrÃ©er des donnÃ©es de test avec checksum
    local test_data="test-data-$(date +%s)"
    echo "$test_data" | sha256sum > /tmp/test-checksum.txt

    # CrÃ©er un ConfigMap avec les donnÃ©es
    microk8s kubectl create configmap integrity-test \
        --from-literal=data="$test_data" \
        -n default

    # Backup
    microk8s kubectl get configmap integrity-test -n default -o yaml > /tmp/integrity-backup.yaml

    # Supprimer
    microk8s kubectl delete configmap integrity-test -n default

    # Restaurer
    microk8s kubectl apply -f /tmp/integrity-backup.yaml

    # VÃ©rifier l'intÃ©gritÃ©
    local restored_data=$(microk8s kubectl get configmap integrity-test -n default -o jsonpath='{.data.data}')
    local restored_checksum=$(echo "$restored_data" | sha256sum)
    local original_checksum=$(cat /tmp/test-checksum.txt)

    # Nettoyer
    microk8s kubectl delete configmap integrity-test -n default

    if [ "$restored_checksum" = "$original_checksum" ]; then
        echo "âœ… IntÃ©gritÃ© des donnÃ©es vÃ©rifiÃ©e"
        return 0
    else
        echo "âŒ Corruption de donnÃ©es dÃ©tectÃ©e"
        return 1
    fi
}

test_performance_metrics() {
    echo "ğŸ“Š Test des mÃ©triques de performance"

    local start_time=$(date +%s%N)

    # Test de backup
    case $BACKUP_TOOL in
        velero)
            velero backup create perf-test-$(date +%s) --include-namespaces=default --wait
            ;;
        *)
            microk8s kubectl get all -n default -o yaml > /tmp/perf-test.yaml
            ;;
    esac

    local backup_time=$(date +%s%N)
    local backup_duration=$(( ($backup_time - $start_time) / 1000000 ))

    # Test de restauration
    case $BACKUP_TOOL in
        velero)
            velero restore create perf-restore-$(date +%s) --from-backup perf-test-* --wait
            ;;
        *)
            microk8s kubectl apply -f /tmp/perf-test.yaml --dry-run=server
            ;;
    esac

    local restore_time=$(date +%s%N)
    local restore_duration=$(( ($restore_time - $backup_time) / 1000000 ))

    echo "â±ï¸ Temps de backup: ${backup_duration}ms"
    echo "â±ï¸ Temps de restauration: ${restore_duration}ms"

    # Seuils de performance (en millisecondes)
    local backup_threshold=30000   # 30 secondes
    local restore_threshold=60000  # 60 secondes

    if [ $backup_duration -lt $backup_threshold ] && [ $restore_duration -lt $restore_threshold ]; then
        echo "âœ… Performance acceptable"
        return 0
    else
        echo "âš ï¸  Performance dÃ©gradÃ©e"
        return 1
    fi
}

# Configuration du scheduler
setup_test_scheduler() {
    echo "ğŸ“… Configuration du scheduler de tests"

    local cron_schedule=""

    case $TEST_SCHEDULE in
        daily)
            cron_schedule="0 3 * * *"  # 3h du matin
            ;;
        weekly)
            cron_schedule="0 3 * * 0"  # Dimanche 3h
            ;;
        monthly)
            cron_schedule="0 3 1 * *"  # 1er du mois 3h
            ;;
        *)
            echo "âŒ Schedule non reconnu: $TEST_SCHEDULE"
            return 1
            ;;
    esac

    # CrÃ©er le cron job
    cat > /etc/cron.d/restore-tests <<EOF
# Tests automatisÃ©s de restauration MicroK8s
SHELL=/bin/bash
PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin

$cron_schedule root /usr/local/bin/automated-restore-tests.sh run_test_suite >> $TEST_LOG_DIR/cron.log 2>&1
EOF

    echo "âœ… Scheduler configurÃ©: $TEST_SCHEDULE ($cron_schedule)"
}

# Menu principal
case "$1" in
    test)
        run_automated_test "$2" "$3"
        ;;
    suite)
        run_test_suite
        ;;
    schedule)
        setup_test_scheduler
        ;;
    *)
        echo "Usage: $0 {test|suite|schedule}"
        echo "  test <name> <function> - ExÃ©cuter un test spÃ©cifique"
        echo "  suite                  - ExÃ©cuter la suite complÃ¨te"
        echo "  schedule               - Configurer le scheduler"
        ;;
esac
```

## Validation et mÃ©triques

### MÃ©triques de test

```bash
#!/bin/bash
# test-metrics.sh

# Collecter et analyser les mÃ©triques de test
collect_test_metrics() {
    echo "ğŸ“Š Collecte des mÃ©triques de test"

    local metrics_file="/var/log/restore-tests/metrics-$(date +%Y%m%d).json"
    local test_name=$1
    local test_status=$2
    local test_duration=$3
    local test_timestamp=$(date -Iseconds)

    # CrÃ©er l'entrÃ©e de mÃ©trique
    local metric_entry=$(cat <<EOF
{
    "timestamp": "$test_timestamp",
    "test_name": "$test_name",
    "status": "$test_status",
    "duration_seconds": $test_duration,
    "backup_tool": "${BACKUP_TOOL:-unknown}",
    "cluster_nodes": $(microk8s kubectl get nodes --no-headers | wc -l),
    "total_pods": $(microk8s kubectl get pods --all-namespaces --no-headers | wc -l),
    "total_namespaces": $(microk8s kubectl get namespaces --no-headers | wc -l)
}
EOF
    )

    # Ajouter au fichier de mÃ©triques
    echo "$metric_entry" >> "$metrics_file"

    # Calculer les statistiques
    calculate_test_statistics
}

# Calculer les statistiques de test
calculate_test_statistics() {
    echo "ğŸ“ˆ Calcul des statistiques de test"

    local metrics_dir="/var/log/restore-tests"
    local stats_file="$metrics_dir/statistics.txt"

    # Analyser les 30 derniers jours
    local total_tests=0
    local successful_tests=0
    local failed_tests=0
    local total_duration=0

    # Parcourir les fichiers de mÃ©triques
    for metric_file in "$metrics_dir"/metrics-*.json; do
        [ -f "$metric_file" ] || continue

        while IFS= read -r line; do
            ((total_tests++))

            local status=$(echo "$line" | jq -r '.status')
            local duration=$(echo "$line" | jq -r '.duration_seconds')

            if [ "$status" = "SUCCESS" ]; then
                ((successful_tests++))
            else
                ((failed_tests++))
            fi

            total_duration=$(echo "$total_duration + $duration" | bc)
        done < "$metric_file"
    done

    # Calculer les moyennes
    local success_rate=0
    local avg_duration=0

    if [ $total_tests -gt 0 ]; then
        success_rate=$(echo "scale=2; $successful_tests * 100 / $total_tests" | bc)
        avg_duration=$(echo "scale=2; $total_duration / $total_tests" | bc)
    fi

    # GÃ©nÃ©rer le rapport
    cat > "$stats_file" <<EOF
=== STATISTIQUES DES TESTS DE RESTAURATION ===
Date de gÃ©nÃ©ration: $(date)

Tests totaux: $total_tests
Tests rÃ©ussis: $successful_tests
Tests Ã©chouÃ©s: $failed_tests
Taux de rÃ©ussite: ${success_rate}%
DurÃ©e moyenne: ${avg_duration}s

Tendances (30 derniers jours):
$(generate_trend_analysis)

Prochains tests programmÃ©s:
$(list_scheduled_tests)
EOF

    echo "âœ… Statistiques gÃ©nÃ©rÃ©es: $stats_file"
}

# Analyser les tendances
generate_trend_analysis() {
    local metrics_dir="/var/log/restore-tests"

    # Analyser les tendances sur 30 jours
    for i in {0..29}; do
        local date=$(date -d "$i days ago" +%Y%m%d)
        local file="$metrics_dir/metrics-$date.json"

        if [ -f "$file" ]; then
            local day_tests=$(wc -l < "$file")
            local day_success=$(grep '"status": "SUCCESS"' "$file" | wc -l)
            local day_rate=0

            if [ $day_tests -gt 0 ]; then
                day_rate=$(echo "scale=0; $day_success * 100 / $day_tests" | bc)
            fi

            echo "$(date -d "$i days ago" +%Y-%m-%d): $day_tests tests, ${day_rate}% rÃ©ussite"
        fi
    done | head -7  # Afficher seulement la derniÃ¨re semaine
}

# Lister les tests programmÃ©s
list_scheduled_tests() {
    if [ -f /etc/cron.d/restore-tests ]; then
        grep -v "^#" /etc/cron.d/restore-tests | awk '{print $1,$2,$3,$4,$5,"- Test automatique"}'
    else
        echo "Aucun test programmÃ©"
    fi
}

# Exporter les mÃ©triques pour Prometheus
export_prometheus_metrics() {
    echo "ğŸ“¤ Export des mÃ©triques Prometheus"

    local metrics_file="/var/lib/prometheus/node-exporter/restore_tests.prom"
    local metrics_dir="/var/log/restore-tests"

    # CrÃ©er le rÃ©pertoire si nÃ©cessaire
    mkdir -p "$(dirname "$metrics_file")"

    # Calculer les mÃ©triques actuelles
    local total_tests=$(find "$metrics_dir" -name "metrics-*.json" -exec wc -l {} \; | awk '{sum+=$1} END {print sum}')
    local last_test_time=$(find "$metrics_dir" -name "metrics-*.json" -exec stat -c %Y {} \; | sort -n | tail -1)
    local last_success=$(grep -h '"status": "SUCCESS"' "$metrics_dir"/metrics-*.json | tail -1 | jq -r '.timestamp' | xargs -I {} date -d {} +%s)
    local last_failure=$(grep -h '"status": "FAILURE"' "$metrics_dir"/metrics-*.json | tail -1 | jq -r '.timestamp' | xargs -I {} date -d {} +%s)

    # GÃ©nÃ©rer le fichier de mÃ©triques Prometheus
    cat > "$metrics_file" <<EOF
# HELP restore_tests_total Total number of restore tests executed
# TYPE restore_tests_total counter
restore_tests_total $total_tests

# HELP restore_tests_last_execution_timestamp Timestamp of last test execution
# TYPE restore_tests_last_execution_timestamp gauge
restore_tests_last_execution_timestamp $last_test_time

# HELP restore_tests_last_success_timestamp Timestamp of last successful test
# TYPE restore_tests_last_success_timestamp gauge
restore_tests_last_success_timestamp ${last_success:-0}

# HELP restore_tests_last_failure_timestamp Timestamp of last failed test
# TYPE restore_tests_last_failure_timestamp gauge
restore_tests_last_failure_timestamp ${last_failure:-0}
EOF

    echo "âœ… MÃ©triques exportÃ©es: $metrics_file"
}
```

### Dashboard de monitoring

```yaml
# grafana-restore-tests-dashboard.json
{
  "dashboard": {
    "title": "Tests de Restauration MicroK8s",
    "panels": [
      {
        "id": 1,
        "title": "Taux de RÃ©ussite",
        "type": "stat",
        "targets": [
          {
            "expr": "rate(restore_tests_success[24h]) / rate(restore_tests_total[24h]) * 100"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percent",
            "thresholds": {
              "mode": "absolute",
              "steps": [
                {"value": 0, "color": "red"},
                {"value": 80, "color": "yellow"},
                {"value": 95, "color": "green"}
              ]
            }
          }
        }
      },
      {
        "id": 2,
        "title": "Temps depuis Dernier Test",
        "type": "stat",
        "targets": [
          {
            "expr": "(time() - restore_tests_last_execution_timestamp) / 3600"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "h",
            "thresholds": {
              "mode": "absolute",
              "steps": [
                {"value": 0, "color": "green"},
                {"value": 24, "color": "yellow"},
                {"value": 168, "color": "red"}
              ]
            }
          }
        }
      },
      {
        "id": 3,
        "title": "Historique des Tests",
        "type": "graph",
        "targets": [
          {
            "expr": "increase(restore_tests_total[1h])",
            "legendFormat": "Tests totaux"
          },
          {
            "expr": "increase(restore_tests_success[1h])",
            "legendFormat": "Tests rÃ©ussis"
          },
          {
            "expr": "increase(restore_tests_failure[1h])",
            "legendFormat": "Tests Ã©chouÃ©s"
          }
        ]
      },
      {
        "id": 4,
        "title": "DurÃ©e des Tests",
        "type": "graph",
        "targets": [
          {
            "expr": "restore_test_duration_seconds",
            "legendFormat": "{{test_type}}"
          }
        ],
        "yaxes": [
          {
            "format": "s",
            "label": "DurÃ©e"
          }
        ]
      }
    ]
  }
}
```

## ScÃ©narios de test avancÃ©s

### Test de corruption de donnÃ©es

```bash
#!/bin/bash
# corruption-test.sh

test_data_corruption_recovery() {
    echo "ğŸ”¬ Test de rÃ©cupÃ©ration aprÃ¨s corruption de donnÃ©es"

    local test_namespace="corruption-test"
    local test_data="Important data that must be preserved"

    # 1. CrÃ©er l'environnement de test
    echo "ğŸ“¦ CrÃ©ation de l'environnement..."
    microk8s kubectl create namespace $test_namespace

    # CrÃ©er une application avec donnÃ©es
    cat <<EOF | microk8s kubectl apply -n $test_namespace -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: critical-data
data:
  data.txt: |
    $test_data
  checksum: $(echo -n "$test_data" | sha256sum | cut -d' ' -f1)
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: data-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: data-app
  template:
    metadata:
      labels:
        app: data-app
    spec:
      containers:
      - name: app
        image: busybox
        command: ['sh', '-c', 'while true; do cat /data/data.txt; sleep 30; done']
        volumeMounts:
        - name: config
          mountPath: /data
      volumes:
      - name: config
        configMap:
          name: critical-data
EOF

    # 2. CrÃ©er un backup
    echo "ğŸ“¸ CrÃ©ation du backup..."
    microk8s kubectl get all,cm -n $test_namespace -o yaml > /tmp/corruption-backup.yaml
    local original_checksum=$(microk8s kubectl get cm critical-data -n $test_namespace -o jsonpath='{.data.checksum}')

    # 3. Simuler une corruption
    echo "ğŸ’¥ Simulation de corruption..."
    microk8s kubectl patch configmap critical-data -n $test_namespace \
        --type='json' -p='[{"op": "replace", "path": "/data/data.txt", "value": "CORRUPTED DATA!!!"}]'

    # VÃ©rifier la corruption
    local corrupted_data=$(microk8s kubectl get cm critical-data -n $test_namespace -o jsonpath='{.data.data\.txt}')
    if [[ "$corrupted_data" == "CORRUPTED DATA!!!" ]]; then
        echo "âœ… Corruption simulÃ©e avec succÃ¨s"
    else
        echo "âŒ Ã‰chec de la simulation de corruption"
        return 1
    fi

    # 4. DÃ©tecter la corruption
    echo "ğŸ” DÃ©tection de la corruption..."
    local current_data=$(microk8s kubectl get cm critical-data -n $test_namespace -o jsonpath='{.data.data\.txt}')
    local current_checksum=$(echo -n "$current_data" | sha256sum | cut -d' ' -f1)

    if [ "$current_checksum" != "$original_checksum" ]; then
        echo "âš ï¸  Corruption dÃ©tectÃ©e! Checksum ne correspond pas."
        echo "  Original: $original_checksum"
        echo "  Actuel: $current_checksum"
    fi

    # 5. Restaurer depuis le backup
    echo "â™»ï¸  Restauration des donnÃ©es non corrompues..."
    microk8s kubectl delete cm critical-data -n $test_namespace
    microk8s kubectl apply -f /tmp/corruption-backup.yaml

    # 6. Valider la restauration
    echo "âœ… Validation de la restauration..."
    local restored_data=$(microk8s kubectl get cm critical-data -n $test_namespace -o jsonpath='{.data.data\.txt}')
    local restored_checksum=$(echo -n "$restored_data" | sha256sum | cut -d' ' -f1)

    if [ "$restored_checksum" == "$original_checksum" ]; then
        echo "âœ… DonnÃ©es restaurÃ©es avec succÃ¨s!"
        echo "  DonnÃ©es: $restored_data"

        # Nettoyer
        microk8s kubectl delete namespace $test_namespace --wait=false
        return 0
    else
        echo "âŒ Ã‰chec de la restauration - les donnÃ©es sont toujours corrompues"
        return 1
    fi
}
```

### Test de montÃ©e en charge

```bash
#!/bin/bash
# load-test-restore.sh

test_restore_under_load() {
    echo "ğŸ”¬ Test de restauration sous charge"

    local test_namespace="load-test"
    local pod_count=50

    # 1. CrÃ©er un namespace avec beaucoup de ressources
    echo "ğŸ“¦ CrÃ©ation de $pod_count pods..."
    microk8s kubectl create namespace $test_namespace

    for i in $(seq 1 $pod_count); do
        cat <<EOF | microk8s kubectl apply -n $test_namespace -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: load-app-$i
spec:
  replicas: 1
  selector:
    matchLabels:
      app: load-app-$i
  template:
    metadata:
      labels:
        app: load-app-$i
    spec:
      containers:
      - name: app
        image: nginx:alpine
        resources:
          requests:
            memory: "10Mi"
            cpu: "10m"
          limits:
            memory: "50Mi"
            cpu: "50m"
EOF
    done

    # 2. Attendre que tous les pods soient prÃªts
    echo "â³ Attente du dÃ©marrage des pods..."
    local ready_pods=0
    local max_wait=120
    local waited=0

    while [ $ready_pods -lt $pod_count ] && [ $waited -lt $max_wait ]; do
        ready_pods=$(microk8s kubectl get pods -n $test_namespace --field-selector=status.phase=Running --no-headers | wc -l)
        echo "  Pods prÃªts: $ready_pods/$pod_count"
        sleep 5
        ((waited+=5))
    done

    # 3. Mesurer les ressources utilisÃ©es
    echo "ğŸ“Š Ressources utilisÃ©es avant backup:"
    microk8s kubectl top nodes
    microk8s kubectl top pods -n $test_namespace | head -10

    # 4. CrÃ©er un backup avec mesure du temps
    echo "ğŸ“¸ CrÃ©ation du backup sous charge..."
    local backup_start=$(date +%s)

    if command -v velero &> /dev/null; then
        velero backup create load-backup-$(date +%s) --include-namespaces=$test_namespace --wait
    else
        microk8s kubectl get all -n $test_namespace -o yaml > /tmp/load-backup.yaml
    fi

    local backup_end=$(date +%s)
    local backup_duration=$((backup_end - backup_start))
    echo "â±ï¸  DurÃ©e du backup: ${backup_duration}s"

    # 5. Supprimer le namespace
    echo "ğŸ—‘ï¸  Suppression du namespace..."
    microk8s kubectl delete namespace $test_namespace --wait=false
    sleep 10

    # 6. Restaurer avec mesure du temps
    echo "â™»ï¸  Restauration sous charge..."
    local restore_start=$(date +%s)

    if command -v velero &> /dev/null; then
        velero restore create load-restore-$(date +%s) --from-backup load-backup-* --wait
    else
        microk8s kubectl apply -f /tmp/load-backup.yaml
    fi

    local restore_end=$(date +%s)
    local restore_duration=$((restore_end - restore_start))
    echo "â±ï¸  DurÃ©e de restauration: ${restore_duration}s"

    # 7. VÃ©rifier la restauration
    echo "ğŸ” VÃ©rification de la restauration..."
    local restored_pods=$(microk8s kubectl get deployments -n $test_namespace --no-headers | wc -l)

    # Nettoyer
    microk8s kubectl delete namespace $test_namespace --wait=false

    # Rapport
    echo ""
    echo "ğŸ“Š RAPPORT DE TEST SOUS CHARGE"
    echo "=============================="
    echo "Pods testÃ©s: $pod_count"
    echo "Pods restaurÃ©s: $restored_pods"
    echo "Temps de backup: ${backup_duration}s"
    echo "Temps de restauration: ${restore_duration}s"
    echo "Ratio backup: $(echo "scale=2; $backup_duration / $pod_count" | bc)s par pod"
    echo "Ratio restauration: $(echo "scale=2; $restore_duration / $pod_count" | bc)s par pod"

    if [ $restored_pods -eq $pod_count ]; then
        echo "âœ… Test rÃ©ussi!"
        return 0
    else
        echo "âŒ Test Ã©chouÃ© - tous les pods n'ont pas Ã©tÃ© restaurÃ©s"
        return 1
    fi
}
```

### Test de cohÃ©rence multi-composants

```bash
#!/bin/bash
# consistency-test.sh

test_multi_component_consistency() {
    echo "ğŸ”¬ Test de cohÃ©rence multi-composants"

    local test_namespace="consistency-test"

    # 1. DÃ©ployer une stack complÃ¨te
    echo "ğŸ“¦ DÃ©ploiement d'une application multi-composants..."
    microk8s kubectl create namespace $test_namespace

    # Base de donnÃ©es
    cat <<EOF | microk8s kubectl apply -n $test_namespace -f -
apiVersion: v1
kind: Secret
metadata:
  name: db-secret
type: Opaque
data:
  password: $(echo -n "dbpass123" | base64)
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: database
spec:
  serviceName: database
  replicas: 1
  selector:
    matchLabels:
      app: database
  template:
    metadata:
      labels:
        app: database
    spec:
      containers:
      - name: postgres
        image: postgres:13-alpine
        env:
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: password
        - name: POSTGRES_DB
          value: testdb
        ports:
        - containerPort: 5432
---
apiVersion: v1
kind: Service
metadata:
  name: database
spec:
  selector:
    app: database
  ports:
  - port: 5432
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend
spec:
  replicas: 2
  selector:
    matchLabels:
      app: backend
  template:
    metadata:
      labels:
        app: backend
    spec:
      containers:
      - name: api
        image: nginx:alpine
        env:
        - name: DB_HOST
          value: database
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: password
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: backend
spec:
  selector:
    app: backend
  ports:
  - port: 80
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
    spec:
      containers:
      - name: web
        image: nginx:alpine
        env:
        - name: API_URL
          value: http://backend
        ports:
        - containerPort: 80
EOF

    # 2. Attendre que tout soit prÃªt
    echo "â³ Attente du dÃ©marrage complet..."
    microk8s kubectl wait --for=condition=ready pod -l app=database -n $test_namespace --timeout=60s
    microk8s kubectl wait --for=condition=ready pod -l app=backend -n $test_namespace --timeout=60s
    microk8s kubectl wait --for=condition=ready pod -l app=frontend -n $test_namespace --timeout=60s

    # 3. Capturer l'Ã©tat de rÃ©fÃ©rence
    echo "ğŸ“¸ Capture de l'Ã©tat de rÃ©fÃ©rence..."
    local ref_state="/tmp/reference-state.json"

    cat > "$ref_state" <<EOF
{
    "timestamp": "$(date -Iseconds)",
    "components": {
        "database": {
            "type": "StatefulSet",
            "replicas": $(microk8s kubectl get statefulset database -n $test_namespace -o jsonpath='{.status.readyReplicas}'),
            "version": "$(microk8s kubectl get statefulset database -n $test_namespace -o jsonpath='{.spec.template.spec.containers[0].image}')"
        },
        "backend": {
            "type": "Deployment",
            "replicas": $(microk8s kubectl get deployment backend -n $test_namespace -o jsonpath='{.status.readyReplicas}'),
            "env_db_host": "$(microk8s kubectl get deployment backend -n $test_namespace -o jsonpath='{.spec.template.spec.containers[0].env[?(@.name=="DB_HOST")].value}')"
        },
        "frontend": {
            "type": "Deployment",
            "replicas": $(microk8s kubectl get deployment frontend -n $test_namespace -o jsonpath='{.status.readyReplicas}'),
            "env_api_url": "$(microk8s kubectl get deployment frontend -n $test_namespace -o jsonpath='{.spec.template.spec.containers[0].env[?(@.name=="API_URL")].value}')"
        }
    },
    "connections": {
        "frontend_to_backend": "http://backend",
        "backend_to_database": "database:5432"
    }
}
EOF

    # 4. CrÃ©er un backup
    echo "ğŸ’¾ CrÃ©ation du backup..."
    microk8s kubectl get all,secret,cm -n $test_namespace -o yaml > /tmp/consistency-backup.yaml

    # 5. Simuler une dÃ©faillance partielle
    echo "ğŸ’¥ Simulation de dÃ©faillance partielle..."
    microk8s kubectl delete deployment backend -n $test_namespace
    microk8s kubectl delete secret db-secret -n $test_namespace

    # 6. Restaurer
    echo "â™»ï¸  Restauration..."
    microk8s kubectl apply -f /tmp/consistency-backup.yaml

    # 7. VÃ©rifier la cohÃ©rence
    echo "ğŸ” VÃ©rification de la cohÃ©rence..."
    sleep 10  # Attendre la stabilisation

    local errors=0

    # VÃ©rifier que tous les composants sont prÃ©sents
    for component in database backend frontend; do
        if ! microk8s kubectl get deployment,statefulset -n $test_namespace | grep -q $component; then
            echo "âŒ Composant manquant: $component"
            ((errors++))
        else
            echo "âœ… Composant restaurÃ©: $component"
        fi
    done

    # VÃ©rifier les connexions
    local backend_db_host=$(microk8s kubectl get deployment backend -n $test_namespace -o jsonpath='{.spec.template.spec.containers[0].env[?(@.name=="DB_HOST")].value}')
    if [ "$backend_db_host" != "database" ]; then
        echo "âŒ Configuration backend incorrecte"
        ((errors++))
    else
        echo "âœ… Configuration backend cohÃ©rente"
    fi

    # VÃ©rifier les secrets
    if ! microk8s kubectl get secret db-secret -n $test_namespace &>/dev/null; then
        echo "âŒ Secret de base de donnÃ©es manquant"
        ((errors++))
    else
        echo "âœ… Secret restaurÃ©"
    fi

    # Nettoyer
    microk8s kubectl delete namespace $test_namespace --wait=false

    # RÃ©sultat
    if [ $errors -eq 0 ]; then
        echo "âœ… Test de cohÃ©rence rÃ©ussi!"
        return 0
    else
        echo "âŒ Test de cohÃ©rence Ã©chouÃ© avec $errors erreurs"
        return 1
    fi
}
```

## Rapports et documentation

### GÃ©nÃ©ration de rapports automatiques

```bash
#!/bin/bash
# generate-test-report.sh

generate_test_report() {
    echo "ğŸ“„ GÃ©nÃ©ration du rapport de test"

    local report_date=$(date +%Y%m%d-%H%M%S)
    local report_dir="/var/log/restore-tests/reports"
    local report_file="$report_dir/test-report-$report_date.html"

    mkdir -p "$report_dir"

    # Collecter les donnÃ©es
    local total_tests=$(find /var/log/restore-tests -name "test-*.log" | wc -l)
    local successful_tests=$(grep -l "SUCCESS" /var/log/restore-tests/test-*.log 2>/dev/null | wc -l)
    local failed_tests=$(grep -l "FAILURE" /var/log/restore-tests/test-*.log 2>/dev/null | wc -l)
    local success_rate=$(echo "scale=2; $successful_tests * 100 / $total_tests" | bc)

    # GÃ©nÃ©rer le rapport HTML
    cat > "$report_file" <<'HTML'
<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <title>Rapport de Tests de Restauration</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            margin: 0;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 12px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            padding: 30px;
        }
        h1 {
            color: #333;
            border-bottom: 3px solid #667eea;
            padding-bottom: 10px;
        }
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }
        .stat-card {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            border-left: 4px solid #667eea;
        }
        .stat-value {
            font-size: 2em;
            font-weight: bold;
            color: #333;
        }
        .stat-label {
            color: #666;
            margin-top: 5px;
        }
        .success { color: #28a745; }
        .failure { color: #dc3545; }
        .warning { color: #ffc107; }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 20px;
        }
        th, td {
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #dee2e6;
        }
        th {
            background: #f8f9fa;
            font-weight: 600;
        }
        .badge {
            padding: 4px 8px;
            border-radius: 4px;
            font-size: 0.85em;
            font-weight: 600;
        }
        .badge-success { background: #d4edda; color: #155724; }
        .badge-danger { background: #f8d7da; color: #721c24; }
        .timeline {
            margin-top: 30px;
        }
        .timeline-item {
            padding: 15px;
            border-left: 3px solid #667eea;
            margin-left: 10px;
            margin-bottom: 20px;
            position: relative;
        }
        .timeline-item::before {
            content: "";
            position: absolute;
            left: -7px;
            top: 20px;
            width: 11px;
            height: 11px;
            border-radius: 50%;
            background: #667eea;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ“Š Rapport de Tests de Restauration MicroK8s</h1>
        <p>GÃ©nÃ©rÃ© le: <strong>$(date '+%Y-%m-%d %H:%M:%S')</strong></p>

        <div class="stats-grid">
            <div class="stat-card">
                <div class="stat-value">$total_tests</div>
                <div class="stat-label">Tests Totaux</div>
            </div>
            <div class="stat-card">
                <div class="stat-value success">$successful_tests</div>
                <div class="stat-label">Tests RÃ©ussis</div>
            </div>
            <div class="stat-card">
                <div class="stat-value failure">$failed_tests</div>
                <div class="stat-label">Tests Ã‰chouÃ©s</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">${success_rate}%</div>
                <div class="stat-label">Taux de RÃ©ussite</div>
            </div>
        </div>

        <h2>ğŸ“ˆ RÃ©sultats DÃ©taillÃ©s</h2>
        <table>
            <thead>
                <tr>
                    <th>Date</th>
                    <th>Type de Test</th>
                    <th>DurÃ©e</th>
                    <th>Statut</th>
                    <th>DÃ©tails</th>
                </tr>
            </thead>
            <tbody>
HTML

    # Ajouter les lignes du tableau
    for log_file in $(ls -t /var/log/restore-tests/test-*.log | head -20); do
        local test_date=$(stat -c %y "$log_file" | cut -d' ' -f1,2 | cut -d'.' -f1)
        local test_type=$(grep "Test:" "$log_file" | head -1 | cut -d':' -f2 | xargs)
        local test_duration=$(grep "DurÃ©e:" "$log_file" | head -1 | cut -d':' -f2 | xargs)
        local test_status=$(grep -q "SUCCESS" "$log_file" && echo "SUCCESS" || echo "FAILURE")
        local badge_class=$([ "$test_status" = "SUCCESS" ] && echo "badge-success" || echo "badge-danger")
        local status_icon=$([ "$test_status" = "SUCCESS" ] && echo "âœ…" || echo "âŒ")

        cat >> "$report_file" <<HTML
                <tr>
                    <td>$test_date</td>
                    <td>$test_type</td>
                    <td>$test_duration</td>
                    <td><span class="badge $badge_class">$status_icon $test_status</span></td>
                    <td><a href="file://$log_file">Voir les logs</a></td>
                </tr>
HTML
    done

    # Continuer le rapport HTML
    cat >> "$report_file" <<'HTML'
            </tbody>
        </table>

        <h2>ğŸ“… Historique RÃ©cent</h2>
        <div class="timeline">
HTML

    # Ajouter les Ã©vÃ©nements rÃ©cents
    for i in {0..6}; do
        local date=$(date -d "$i days ago" +%Y-%m-%d)
        local day_tests=$(find /var/log/restore-tests -name "test-*.log" -newermt "$date 00:00" ! -newermt "$date 23:59" | wc -l)
        local day_success=$(find /var/log/restore-tests -name "test-*.log" -newermt "$date 00:00" ! -newermt "$date 23:59" -exec grep -l "SUCCESS" {} \; | wc -l)

        if [ $day_tests -gt 0 ]; then
            cat >> "$report_file" <<HTML
            <div class="timeline-item">
                <strong>$date</strong><br>
                Tests exÃ©cutÃ©s: $day_tests<br>
                RÃ©ussis: $day_success<br>
                Taux: $(echo "scale=1; $day_success * 100 / $day_tests" | bc)%
            </div>
HTML
        fi
    done

    # Finaliser le rapport HTML
    cat >> "$report_file" <<'HTML'
        </div>

        <h2>ğŸ” Analyses et Recommandations</h2>
        <div style="background: #f8f9fa; padding: 20px; border-radius: 8px; margin-top: 20px;">
HTML

    # Ajouter les recommandations basÃ©es sur les rÃ©sultats
    if (( $(echo "$success_rate < 95" | bc -l) )); then
        cat >> "$report_file" <<'HTML'
            <p>âš ï¸ <strong>Attention:</strong> Le taux de rÃ©ussite est infÃ©rieur Ã  95%. Actions recommandÃ©es:</p>
            <ul>
                <li>VÃ©rifier la validitÃ© des backups</li>
                <li>Examiner les logs des tests Ã©chouÃ©s</li>
                <li>Valider la configuration de l'outil de backup</li>
                <li>Augmenter la frÃ©quence des tests</li>
            </ul>
HTML
    else
        cat >> "$report_file" <<'HTML'
            <p>âœ… <strong>Excellent:</strong> Le taux de rÃ©ussite est supÃ©rieur Ã  95%.</p>
            <ul>
                <li>Continuer les tests rÃ©guliers</li>
                <li>Envisager des scÃ©narios de test plus complexes</li>
                <li>Documenter les procÃ©dures qui fonctionnent bien</li>
            </ul>
HTML
    fi

    cat >> "$report_file" <<'HTML'
        </div>

        <h2>ğŸ“Š MÃ©triques de Performance</h2>
        <canvas id="performanceChart" width="400" height="200"></canvas>

        <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
        <script>
            // Graphique de performance (exemple)
            const ctx = document.getElementById('performanceChart').getContext('2d');
            const chart = new Chart(ctx, {
                type: 'line',
                data: {
                    labels: ['Lun', 'Mar', 'Mer', 'Jeu', 'Ven', 'Sam', 'Dim'],
                    datasets: [{
                        label: 'DurÃ©e des tests (secondes)',
                        data: [45, 52, 48, 55, 47, 50, 49],
                        borderColor: '#667eea',
                        tension: 0.1
                    }]
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false
                }
            });
        </script>

        <footer style="margin-top: 50px; padding-top: 20px; border-top: 1px solid #dee2e6; text-align: center; color: #666;">
            <p>Rapport gÃ©nÃ©rÃ© automatiquement par le systÃ¨me de tests de restauration MicroK8s</p>
            <p>Pour plus d'informations, consultez les logs dans: <code>/var/log/restore-tests/</code></p>
        </footer>
    </div>
</body>
</html>
HTML

    echo "âœ… Rapport gÃ©nÃ©rÃ©: $report_file"

    # Optionnel: ouvrir le rapport dans le navigateur
    if command -v xdg-open &> /dev/null; then
        xdg-open "$report_file" 2>/dev/null &
    fi
}

# GÃ©nÃ©rer un rapport PDF
generate_pdf_report() {
    local html_report=$1
    local pdf_report="${html_report%.html}.pdf"

    if command -v wkhtmltopdf &> /dev/null; then
        wkhtmltopdf "$html_report" "$pdf_report"
        echo "âœ… Rapport PDF gÃ©nÃ©rÃ©: $pdf_report"
    else
        echo "âš ï¸  wkhtmltopdf non installÃ©. Installation: sudo apt-get install wkhtmltopdf"
    fi
}

# Envoyer le rapport par email
send_report_email() {
    local report_file=$1
    local recipient=${2:-$NOTIFICATION_EMAIL}

    if [ -z "$recipient" ]; then
        echo "âš ï¸  Aucun destinataire email configurÃ©"
        return 1
    fi

    local subject="Rapport de Tests de Restauration - $(date +%Y-%m-%d)"
    local body="Veuillez trouver ci-joint le rapport des tests de restauration.

RÃ©sumÃ©:
- Tests totaux: $total_tests
- Tests rÃ©ussis: $successful_tests
- Taux de rÃ©ussite: ${success_rate}%

Cordialement,
SystÃ¨me de Tests AutomatisÃ©s"

    # Envoyer l'email avec piÃ¨ce jointe
    echo "$body" | mail -s "$subject" -a "$report_file" "$recipient"
    echo "âœ… Rapport envoyÃ© Ã : $recipient"
}
```

### Documentation des procÃ©dures

```bash
#!/bin/bash
# generate-documentation.sh

generate_test_documentation() {
    echo "ğŸ“š GÃ©nÃ©ration de la documentation des tests"

    local doc_dir="/var/log/restore-tests/documentation"
    local doc_file="$doc_dir/test-procedures-$(date +%Y%m%d).md"

    mkdir -p "$doc_dir"

    cat > "$doc_file" <<'MARKDOWN'
# Documentation des Tests de Restauration MicroK8s

## Vue d'ensemble

Cette documentation dÃ©crit les procÃ©dures de test de restauration pour l'environnement MicroK8s.

**DerniÃ¨re mise Ã  jour:** $(date +%Y-%m-%d)

## Table des matiÃ¨res

1. [Objectifs des tests](#objectifs)
2. [Types de tests](#types)
3. [ProcÃ©dures](#procedures)
4. [MÃ©triques](#metriques)
5. [Troubleshooting](#troubleshooting)
6. [Contacts](#contacts)

## Objectifs des tests {#objectifs}

Les tests de restauration visent Ã  :
- âœ… Valider la capacitÃ© de rÃ©cupÃ©ration aprÃ¨s incident
- âœ… Mesurer les temps de restauration (RTO)
- âœ… VÃ©rifier l'intÃ©gritÃ© des donnÃ©es restaurÃ©es
- âœ… Former l'Ã©quipe aux procÃ©dures d'urgence
- âœ… Identifier les points d'amÃ©lioration

## Types de tests {#types}

### 1. Test Partiel
- **FrÃ©quence:** Quotidienne
- **DurÃ©e:** 5-10 minutes
- **Scope:** Un namespace ou une application
- **Automatisation:** ComplÃ¨te

### 2. Test Complet
- **FrÃ©quence:** Hebdomadaire
- **DurÃ©e:** 30-60 minutes
- **Scope:** Cluster entier
- **Automatisation:** Semi-automatique

### 3. Test de Disaster Recovery
- **FrÃ©quence:** Mensuelle
- **DurÃ©e:** 2-4 heures
- **Scope:** Simulation de perte totale
- **Automatisation:** Manuelle avec scripts

## ProcÃ©dures {#procedures}

### ProcÃ©dure de Test Partiel

```bash
# 1. SÃ©lectionner le namespace Ã  tester
NAMESPACE="test-namespace"

# 2. CrÃ©er un backup
velero backup create test-backup --include-namespaces=$NAMESPACE

# 3. Supprimer des ressources
kubectl delete deployment test-app -n $NAMESPACE

# 4. Restaurer
velero restore create --from-backup test-backup

# 5. Valider
kubectl get all -n $NAMESPACE
```

### ProcÃ©dure de Test Complet

```bash
# 1. Notification de maintenance
echo "Maintenance programmÃ©e pour test de restauration"

# 2. Backup complet
velero backup create full-backup --wait

# 3. Simulation de perte
for ns in app-1 app-2 app-3; do
    kubectl delete namespace $ns --wait=false
done

# 4. Restauration
velero restore create --from-backup full-backup --wait

# 5. Validation
./validate-restoration.sh
```

### ProcÃ©dure de Disaster Recovery

Voir le document sÃ©parÃ©: `disaster-recovery-procedure.md`

## MÃ©triques {#metriques}

### MÃ©triques clÃ©s Ã  surveiller

| MÃ©trique | Objectif | Seuil d'alerte |
|----------|----------|----------------|
| RTO (Recovery Time Objective) | < 1 heure | > 2 heures |
| RPO (Recovery Point Objective) | < 4 heures | > 8 heures |
| Taux de rÃ©ussite des tests | > 95% | < 90% |
| Temps de backup | < 30 min | > 1 heure |
| Temps de restauration | < 45 min | > 90 min |

### Dashboard Grafana

AccÃ¨s: https://monitoring.local/dashboard/restore-tests

## Troubleshooting {#troubleshooting}

### ProblÃ¨me: Test Ã©chouÃ© avec timeout

**SymptÃ´mes:**
- Le test se termine avec une erreur de timeout
- Les pods ne deviennent pas Ready

**Solutions:**
1. VÃ©rifier les ressources disponibles
2. Augmenter les timeouts dans les scripts
3. VÃ©rifier les logs des pods

```bash
kubectl describe pod <pod-name>
kubectl logs <pod-name> --previous
```

### ProblÃ¨me: DonnÃ©es corrompues aprÃ¨s restauration

**SymptÃ´mes:**
- Les checksums ne correspondent pas
- Applications en erreur aprÃ¨s restauration

**Solutions:**
1. VÃ©rifier l'intÃ©gritÃ© du backup
2. Tester avec un backup plus ancien
3. VÃ©rifier la configuration de l'outil de backup

### ProblÃ¨me: Restauration incomplÃ¨te

**SymptÃ´mes:**
- Certaines ressources manquent
- Erreurs de dÃ©pendances

**Solutions:**
1. VÃ©rifier l'ordre de restauration
2. S'assurer que tous les namespaces sont inclus
3. VÃ©rifier les RBAC et permissions

## Contacts {#contacts}

| RÃ´le | Nom | Email | TÃ©lÃ©phone |
|------|-----|-------|-----------|
| Responsable Infrastructure | Jean Dupont | jean@example.com | +33 1 23 45 67 89 |
| Admin Kubernetes | Marie Martin | marie@example.com | +33 1 23 45 67 90 |
| Support 24/7 | - | support@example.com | +33 1 23 45 67 00 |

## Historique des modifications

| Date | Version | Modifications | Auteur |
|------|---------|--------------|---------|
| $(date +%Y-%m-%d) | 1.0 | CrÃ©ation initiale | System |

---

*Cette documentation est gÃ©nÃ©rÃ©e automatiquement. Pour toute modification, Ã©diter le script `generate-documentation.sh`*
MARKDOWN

    echo "âœ… Documentation gÃ©nÃ©rÃ©e: $doc_file"
}
```

## Bonnes pratiques et recommandations

### Checklist des bonnes pratiques

```bash
#!/bin/bash
# best-practices-check.sh

check_restore_test_best_practices() {
    echo "ğŸ” VÃ©rification des bonnes pratiques"
    echo "===================================="

    local score=0
    local max_score=10

    # 1. Tests rÃ©guliers
    echo -n "1. Tests rÃ©guliers programmÃ©s... "
    if [ -f /etc/cron.d/restore-tests ]; then
        echo "âœ…"
        ((score++))
    else
        echo "âŒ Configurer les tests automatiques"
    fi

    # 2. Tests variÃ©s
    echo -n "2. DiffÃ©rents types de tests... "
    local test_types=$(ls /var/log/restore-tests/test-*.log 2>/dev/null | xargs grep "Test:" | cut -d':' -f3 | sort -u | wc -l)
    if [ $test_types -ge 3 ]; then
        echo "âœ…"
        ((score++))
    else
        echo "âŒ Diversifier les scÃ©narios de test"
    fi

    # 3. Documentation Ã  jour
    echo -n "3. Documentation rÃ©cente... "
    local doc_age=$(find /var/log/restore-tests/documentation -name "*.md" -mtime -30 2>/dev/null | wc -l)
    if [ $doc_age -gt 0 ]; then
        echo "âœ…"
        ((score++))
    else
        echo "âŒ Mettre Ã  jour la documentation"
    fi

    # 4. Monitoring actif
    echo -n "4. MÃ©triques collectÃ©es... "
    if [ -f /var/lib/prometheus/node-exporter/restore_tests.prom ]; then
        echo "âœ…"
        ((score++))
    else
        echo "âŒ Configurer le monitoring"
    fi

    # 5. Notifications configurÃ©es
    echo -n "5. Notifications configurÃ©es... "
    if [ -n "$NOTIFICATION_EMAIL" ] || [ -n "$SLACK_WEBHOOK" ]; then
        echo "âœ…"
        ((score++))
    else
        echo "âŒ Configurer les alertes"
    fi

    # 6. Logs archivÃ©s
    echo -n "6. Logs archivÃ©s... "
    local old_logs=$(find /var/log/restore-tests -name "*.log" -mtime +30 | wc -l)
    if [ $old_logs -eq 0 ]; then
        echo "âœ…"
        ((score++))
    else
        echo "âš ï¸  $old_logs anciens logs Ã  archiver"
    fi

    # 7. Tests rÃ©ussis rÃ©cemment
    echo -n "7. Tests rÃ©cents rÃ©ussis... "
    local recent_success=$(find /var/log/restore-tests -name "test-*.log" -mtime -7 -exec grep -l "SUCCESS" {} \; | wc -l)
    if [ $recent_success -gt 0 ]; then
        echo "âœ…"
        ((score++))
    else
        echo "âŒ Aucun test rÃ©ussi cette semaine"
    fi

    # 8. Environnement de test isolÃ©
    echo -n "8. Environnement de test dÃ©diÃ©... "
    if microk8s kubectl get namespace | grep -q "restore-test"; then
        echo "âœ…"
        ((score++))
    else
        echo "âš ï¸  CrÃ©er un namespace de test dÃ©diÃ©"
    fi

    # 9. ProcÃ©dures de rollback
    echo -n "9. ProcÃ©dures de rollback documentÃ©es... "
    if [ -f /var/log/restore-tests/documentation/rollback-procedure.md ]; then
        echo "âœ…"
        ((score++))
    else
        echo "âŒ Documenter les procÃ©dures de rollback"
    fi

    # 10. Formation de l'Ã©quipe
    echo -n "10. Ã‰quipe formÃ©e... "
    if [ -f /var/log/restore-tests/training-log.txt ]; then
        echo "âœ…"
        ((score++))
    else
        echo "âš ï¸  Planifier une formation"
    fi

    # RÃ©sultat
    echo ""
    echo "======================================"
    echo "Score: $score/$max_score"

    if [ $score -ge 8 ]; then
        echo "ğŸ† Excellent! Continuez ainsi."
    elif [ $score -ge 6 ]; then
        echo "ğŸ‘ Bien, mais des amÃ©liorations sont possibles."
    elif [ $score -ge 4 ]; then
        echo "âš ï¸  Attention, plusieurs points Ã  amÃ©liorer."
    else
        echo "âŒ Critique! Actions urgentes requises."
    fi

    # Recommandations
    echo ""
    echo "ğŸ“‹ Recommandations prioritaires:"

    if [ $score -lt $max_score ]; then
        echo "1. Automatiser les tests manquants"
        echo "2. Documenter toutes les procÃ©dures"
        echo "3. Former l'Ã©quipe rÃ©guliÃ¨rement"
        echo "4. Surveiller les mÃ©triques de performance"
        echo "5. Tester des scÃ©narios de plus en plus complexes"
    else
        echo "â€¢ Maintenir le niveau actuel"
        echo "â€¢ Explorer des scÃ©narios avancÃ©s"
        echo "â€¢ Partager les bonnes pratiques"
    fi
}

# ExÃ©cution
check_restore_test_best_practices
```

### Plan de test mensuel

```yaml
# monthly-test-plan.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: monthly-test-plan
  namespace: kube-system
data:
  plan.yaml: |
    monthly_test_schedule:
      week_1:
        monday:
          - test: partial_restore
            namespaces: ["default", "production"]
            time: "03:00"
        wednesday:
          - test: data_integrity
            scope: all_databases
            time: "03:00"
        friday:
          - test: performance_baseline
            load: normal
            time: "03:00"

      week_2:
        monday:
          - test: full_restore
            scope: non_critical_apps
            time: "03:00"
        thursday:
          - test: corruption_recovery
            target: test_database
            time: "03:00"

      week_3:
        tuesday:
          - test: multi_component
            apps: ["frontend", "backend", "database"]
            time: "03:00"
        friday:
          - test: load_test
            pods: 100
            time: "03:00"

      week_4:
        monday:
          - test: disaster_recovery
            scenario: complete_failure
            time: "02:00"
            duration: "4h"
            notification: team
        friday:
          - test: cross_cluster_restore
            source: production
            target: staging
            time: "20:00"

      monthly_review:
        last_friday:
          - generate_reports: true
          - team_meeting: true
          - update_documentation: true
          - plan_next_month: true
```

## Conclusion

### Checklist finale des tests de restauration

- [ ] **Configuration de base**
  - [ ] Environnement de test isolÃ© crÃ©Ã©
  - [ ] Scripts de test installÃ©s
  - [ ] Permissions configurÃ©es

- [ ] **Tests automatisÃ©s**
  - [ ] Tests quotidiens programmÃ©s
  - [ ] Tests hebdomadaires configurÃ©s
  - [ ] Tests mensuels planifiÃ©s

- [ ] **Monitoring**
  - [ ] MÃ©triques collectÃ©es
  - [ ] Dashboard configurÃ©
  - [ ] Alertes actives

- [ ] **Documentation**
  - [ ] ProcÃ©dures documentÃ©es
  - [ ] Contacts Ã  jour
  - [ ] Runbooks crÃ©Ã©s

- [ ] **Validation**
  - [ ] Tests rÃ©ussis > 95%
  - [ ] RTO/RPO respectÃ©s
  - [ ] Ã‰quipe formÃ©e

- [ ] **AmÃ©lioration continue**
  - [ ] Revues mensuelles
  - [ ] ScÃ©narios mis Ã  jour
  - [ ] LeÃ§ons apprises documentÃ©es

Les tests de restauration ne sont pas une option mais une nÃ©cessitÃ©. Un backup non testÃ© est comme une assurance dont vous n'Ãªtes pas sÃ»r qu'elle fonctionne. Avec les outils et procÃ©dures dÃ©crits dans cette section, vous pouvez transformer les tests de restauration d'une corvÃ©e ponctuelle en un processus automatisÃ© et fiable qui vous donne confiance dans votre capacitÃ© Ã  rÃ©cupÃ©rer aprÃ¨s un incident.

**Rappel important:** La rÃ©gularitÃ© est la clÃ©. Mieux vaut des tests simples mais frÃ©quents que des tests complexes mais rares. Commencez petit, automatisez progressivement, et amÃ©liorez continuellement vos procÃ©dures basÃ©es sur les rÃ©sultats et les leÃ§ons apprises.

â­ï¸
