üîù Retour au [Sommaire](/SOMMAIRE.md)

# Annexe B - Templates de manifestes YAML

## Introduction aux Manifestes YAML

Les manifestes YAML sont le langage de configuration de Kubernetes. Ils d√©crivent l'√©tat d√©sir√© de vos applications et ressources dans le cluster. Cette annexe fournit une collection de templates pr√™ts √† l'emploi, comment√©s et adaptables pour vos besoins.

### Qu'est-ce qu'un Manifeste YAML ?

Un manifeste YAML est un fichier texte qui d√©crit une ou plusieurs ressources Kubernetes. Il suit une structure pr√©cise avec quatre √©l√©ments essentiels :

- **apiVersion** : La version de l'API Kubernetes utilis√©e
- **kind** : Le type de ressource (Pod, Service, Deployment, etc.)
- **metadata** : Les m√©tadonn√©es (nom, labels, annotations)
- **spec** : La sp√©cification d√©taill√©e de la ressource

### Pourquoi Utiliser des Templates ?

Les templates vous permettent de :
- **Gagner du temps** en √©vitant de r√©√©crire les m√™mes structures
- **√âviter les erreurs** de syntaxe et de configuration
- **Apprendre** les bonnes pratiques par l'exemple
- **Standardiser** vos d√©ploiements
- **Documenter** votre infrastructure as code

## Templates de Base

### 1. Pod Simple

Le Pod est l'unit√© de base dans Kubernetes. Voici un template minimal :

```yaml
# pod-simple.yaml
# Un Pod basique avec un seul conteneur
apiVersion: v1
kind: Pod
metadata:
  name: mon-pod-simple
  namespace: default  # Namespace o√π cr√©er le pod
  labels:
    app: mon-app
    environment: dev
spec:
  containers:
  - name: mon-conteneur
    image: nginx:1.21  # Image Docker √† utiliser
    ports:
    - containerPort: 80  # Port expos√© par le conteneur
    resources:
      # Limites de ressources pour √©viter la surconsommation
      requests:
        memory: "64Mi"
        cpu: "250m"
      limits:
        memory: "128Mi"
        cpu: "500m"
```

### 2. Deployment Complet

Un Deployment g√®re plusieurs r√©pliques de votre application avec strat√©gie de mise √† jour :

```yaml
# deployment-complet.yaml
# Deployment avec toutes les options essentielles
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mon-app-deployment
  namespace: apps  # Cr√©er ce namespace au pr√©alable
  labels:
    app: mon-app
    version: v1.0.0
  annotations:
    description: "Application web principale"
spec:
  replicas: 3  # Nombre de pods √† maintenir
  strategy:
    type: RollingUpdate  # Mise √† jour progressive
    rollingUpdate:
      maxSurge: 1        # Max pods suppl√©mentaires pendant update
      maxUnavailable: 1  # Max pods indisponibles pendant update
  selector:
    matchLabels:
      app: mon-app
  template:
    metadata:
      labels:
        app: mon-app
        version: v1.0.0
    spec:
      containers:
      - name: app-container
        image: mon-registry/mon-app:1.0.0
        imagePullPolicy: IfNotPresent  # Always, Never, IfNotPresent
        ports:
        - containerPort: 8080
          name: http
          protocol: TCP

        # Variables d'environnement
        env:
        - name: NODE_ENV
          value: "production"
        - name: PORT
          value: "8080"
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: database-url

        # Sondes de sant√©
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30  # Attendre avant premi√®re v√©rification
          periodSeconds: 10        # V√©rifier toutes les 10s
          timeoutSeconds: 5
          failureThreshold: 3       # Red√©marrer apr√®s 3 √©checs

        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 3
          successThreshold: 1
          failureThreshold: 3

        # Ressources
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "500m"

        # Montage de volumes
        volumeMounts:
        - name: config-volume
          mountPath: /app/config
        - name: data-volume
          mountPath: /app/data

      # D√©finition des volumes
      volumes:
      - name: config-volume
        configMap:
          name: app-config
      - name: data-volume
        persistentVolumeClaim:
          claimName: app-data-pvc
```

### 3. Service ClusterIP

Expose votre application √† l'int√©rieur du cluster :

```yaml
# service-clusterip.yaml
# Service accessible uniquement depuis l'int√©rieur du cluster
apiVersion: v1
kind: Service
metadata:
  name: mon-app-service
  namespace: apps
  labels:
    app: mon-app
spec:
  type: ClusterIP  # Type par d√©faut, accessible en interne seulement
  selector:
    app: mon-app  # S√©lectionne les pods avec ce label
  ports:
  - port: 80        # Port du service
    targetPort: 8080  # Port du conteneur
    protocol: TCP
    name: http
  sessionAffinity: None  # ou "ClientIP" pour sticky sessions
```

### 4. Service NodePort

Expose votre application sur un port de chaque node :

```yaml
# service-nodeport.yaml
# Service accessible depuis l'ext√©rieur via port du node
apiVersion: v1
kind: Service
metadata:
  name: mon-app-nodeport
  namespace: apps
spec:
  type: NodePort
  selector:
    app: mon-app
  ports:
  - port: 80
    targetPort: 8080
    nodePort: 30080  # Port sur le node (30000-32767)
    protocol: TCP
    name: http
```

### 5. Service LoadBalancer

Pour exposition externe avec MetalLB :

```yaml
# service-loadbalancer.yaml
# Service avec LoadBalancer (n√©cessite MetalLB sur MicroK8s)
apiVersion: v1
kind: Service
metadata:
  name: mon-app-lb
  namespace: apps
  annotations:
    # Annotations sp√©cifiques MetalLB (optionnel)
    metallb.universe.tf/address-pool: production-pool
spec:
  type: LoadBalancer
  selector:
    app: mon-app
  ports:
  - port: 80
    targetPort: 8080
    protocol: TCP
    name: http
  - port: 443
    targetPort: 8443
    protocol: TCP
    name: https
  # IP fixe optionnelle (doit √™tre dans la plage MetalLB)
  # loadBalancerIP: 192.168.1.200
```

## Templates d'Ingress

### 6. Ingress NGINX Basic

Route le trafic HTTP/HTTPS vers vos services :

```yaml
# ingress-basic.yaml
# Ingress simple pour un seul service
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: mon-app-ingress
  namespace: apps
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    # Redirection HTTP vers HTTPS
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
spec:
  ingressClassName: nginx  # ou "public" selon votre configuration
  rules:
  - host: mon-app.example.com  # Votre domaine
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: mon-app-service
            port:
              number: 80
```

### 7. Ingress Multi-Path

Route diff√©rents chemins vers diff√©rents services :

```yaml
# ingress-multi-path.yaml
# Ingress avec multiple chemins et services
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: multi-app-ingress
  namespace: apps
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /$2
    nginx.ingress.kubernetes.io/use-regex: "true"
spec:
  ingressClassName: nginx
  rules:
  - host: apps.example.com
    http:
      paths:
      # Application principale sur /
      - path: /
        pathType: Prefix
        backend:
          service:
            name: main-app-service
            port:
              number: 80

      # API sur /api
      - path: /api(/|$)(.*)
        pathType: Prefix
        backend:
          service:
            name: api-service
            port:
              number: 3000

      # Interface admin sur /admin
      - path: /admin(/|$)(.*)
        pathType: Prefix
        backend:
          service:
            name: admin-service
            port:
              number: 8080
```

### 8. Ingress avec TLS/SSL

Configuration avec certificat SSL :

```yaml
# ingress-tls.yaml
# Ingress avec certificat TLS (HTTPS)
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: secure-app-ingress
  namespace: apps
  annotations:
    # Cert-Manager pour certificats Let's Encrypt automatiques
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
spec:
  ingressClassName: nginx
  tls:
  - hosts:
    - secure-app.example.com
    secretName: secure-app-tls  # Secret contenant le certificat
  rules:
  - host: secure-app.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: secure-app-service
            port:
              number: 80
```

## Templates de Stockage

### 9. PersistentVolumeClaim

Demande de stockage persistant :

```yaml
# pvc-standard.yaml
# PersistentVolumeClaim pour stockage persistant
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: app-data-pvc
  namespace: apps
  labels:
    app: mon-app
spec:
  accessModes:
    - ReadWriteOnce  # RWO: un seul pod en √©criture
    # - ReadOnlyMany   # ROX: plusieurs pods en lecture seule
    # - ReadWriteMany  # RWX: plusieurs pods en √©criture (rare)
  resources:
    requests:
      storage: 5Gi  # Taille du volume
  storageClassName: microk8s-hostpath  # Classe de stockage MicroK8s
  # volumeMode: Filesystem  # ou "Block" pour stockage bloc
```

### 10. StatefulSet avec Stockage

Pour applications avec √©tat (bases de donn√©es, etc.) :

```yaml
# statefulset-with-storage.yaml
# StatefulSet pour applications avec √©tat persistant
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres-db
  namespace: apps
spec:
  serviceName: postgres-service
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:14
        ports:
        - containerPort: 5432
          name: postgres
        env:
        - name: POSTGRES_DB
          value: "myappdb"
        - name: POSTGRES_USER
          value: "appuser"
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: password
        - name: PGDATA
          value: /var/lib/postgresql/data/pgdata
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
  # Template de PVC pour chaque r√©plique
  volumeClaimTemplates:
  - metadata:
      name: postgres-storage
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: microk8s-hostpath
      resources:
        requests:
          storage: 10Gi
```

## Templates de Configuration

### 11. ConfigMap

Pour stocker la configuration non-sensible :

```yaml
# configmap-app.yaml
# ConfigMap pour configuration d'application
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: apps
data:
  # Valeurs simples
  app.name: "Mon Application"
  app.version: "1.0.0"
  log.level: "info"

  # Fichier de configuration complet
  application.yaml: |
    server:
      port: 8080
      host: 0.0.0.0
    database:
      host: postgres-service
      port: 5432
      name: myappdb
    cache:
      enabled: true
      ttl: 3600
    features:
      - name: feature1
        enabled: true
      - name: feature2
        enabled: false

  # Script d'initialisation
  init.sh: |
    #!/bin/bash
    echo "Initialisation de l'application..."
    # Cr√©er les r√©pertoires n√©cessaires
    mkdir -p /app/data /app/logs
    # D√©finir les permissions
    chmod 755 /app/data /app/logs
    echo "Initialisation termin√©e"
```

### 12. Secret

Pour stocker des donn√©es sensibles :

```yaml
# secret-app.yaml
# Secret pour donn√©es sensibles (mots de passe, tokens, etc.)
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
  namespace: apps
type: Opaque  # Type g√©n√©rique
data:
  # Les valeurs doivent √™tre encod√©es en base64
  # echo -n "monmotdepasse" | base64
  database-password: bW9ubW90ZGVwYXNzZQ==
  api-key: YWJjZGVmZ2hpams=
  jwt-secret: c3VwZXJzZWNyZXQ=
---
# Alternative avec stringData (auto-encod√©)
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets-v2
  namespace: apps
type: Opaque
stringData:
  database-url: "postgresql://user:pass@postgres:5432/mydb"
  redis-url: "redis://redis-service:6379"
  smtp-password: "smtp-secret-password"
```

### 13. Secret TLS

Pour certificats SSL/TLS :

```yaml
# secret-tls.yaml
# Secret pour certificat TLS
apiVersion: v1
kind: Secret
metadata:
  name: app-tls-secret
  namespace: apps
type: kubernetes.io/tls
data:
  # G√©n√©rer avec : cat cert.crt | base64 -w 0
  tls.crt: LS0tLS1CRUdJTi... # Certificat encod√© base64
  tls.key: LS0tLS1CRUdJTi... # Cl√© priv√©e encod√©e base64
```

## Templates de Jobs et CronJobs

### 14. Job One-Time

Pour t√¢ches ponctuelles :

```yaml
# job-backup.yaml
# Job pour ex√©cuter une t√¢che unique
apiVersion: batch/v1
kind: Job
metadata:
  name: database-backup
  namespace: apps
spec:
  completions: 1  # Nombre d'ex√©cutions r√©ussies souhait√©es
  parallelism: 1  # Nombre de pods en parall√®le
  backoffLimit: 3  # Nombre de tentatives en cas d'√©chec
  ttlSecondsAfterFinished: 3600  # Nettoyer apr√®s 1h
  template:
    metadata:
      labels:
        job: database-backup
    spec:
      restartPolicy: Never  # ou OnFailure
      containers:
      - name: backup
        image: postgres:14
        command:
        - /bin/bash
        - -c
        - |
          echo "D√©marrage du backup..."
          PGPASSWORD=$POSTGRES_PASSWORD pg_dump \
            -h postgres-service \
            -U $POSTGRES_USER \
            -d $POSTGRES_DB \
            > /backup/db-$(date +%Y%m%d-%H%M%S).sql
          echo "Backup termin√©"
        env:
        - name: POSTGRES_USER
          value: "appuser"
        - name: POSTGRES_DB
          value: "myappdb"
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: password
        volumeMounts:
        - name: backup-volume
          mountPath: /backup
      volumes:
      - name: backup-volume
        persistentVolumeClaim:
          claimName: backup-pvc
```

### 15. CronJob R√©current

Pour t√¢ches planifi√©es :

```yaml
# cronjob-cleanup.yaml
# CronJob pour t√¢ches r√©currentes
apiVersion: batch/v1
kind: CronJob
metadata:
  name: log-cleanup
  namespace: apps
spec:
  schedule: "0 2 * * *"  # Tous les jours √† 2h du matin
  # Format: minute heure jour mois jour-semaine
  # Exemples:
  # "*/5 * * * *"    - Toutes les 5 minutes
  # "0 */6 * * *"    - Toutes les 6 heures
  # "0 0 * * 0"      - Tous les dimanches √† minuit
  # "0 0 1 * *"      - Premier jour du mois √† minuit

  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          containers:
          - name: cleanup
            image: busybox:1.35
            command:
            - /bin/sh
            - -c
            - |
              echo "Nettoyage des logs de plus de 7 jours..."
              find /logs -type f -name "*.log" -mtime +7 -delete
              echo "Nettoyage termin√©"
            volumeMounts:
            - name: logs-volume
              mountPath: /logs
          volumes:
          - name: logs-volume
            persistentVolumeClaim:
              claimName: logs-pvc
  successfulJobsHistoryLimit: 3  # Garder 3 derniers jobs r√©ussis
  failedJobsHistoryLimit: 1      # Garder 1 dernier job √©chou√©
  concurrencyPolicy: Forbid       # Forbid, Allow, Replace
```

## Templates RBAC (S√©curit√©)

### 16. ServiceAccount et Role

Configuration des permissions :

```yaml
# rbac-app.yaml
# Configuration RBAC pour une application
---
# ServiceAccount pour l'application
apiVersion: v1
kind: ServiceAccount
metadata:
  name: app-service-account
  namespace: apps
---
# Role avec permissions sp√©cifiques
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: app-role
  namespace: apps
rules:
# Permissions sur les ConfigMaps
- apiGroups: [""]
  resources: ["configmaps"]
  verbs: ["get", "list", "watch"]
# Permissions sur les Secrets (lecture seule)
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get"]
# Permissions sur les Pods (pour monitoring)
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list"]
---
# RoleBinding pour lier le Role au ServiceAccount
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: app-rolebinding
  namespace: apps
subjects:
- kind: ServiceAccount
  name: app-service-account
  namespace: apps
roleRef:
  kind: Role
  name: app-role
  apiGroup: rbac.authorization.k8s.io
```

### 17. NetworkPolicy

Isolation r√©seau entre pods :

```yaml
# networkpolicy-app.yaml
# NetworkPolicy pour contr√¥ler le trafic r√©seau
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: app-network-policy
  namespace: apps
spec:
  podSelector:
    matchLabels:
      app: mon-app
  policyTypes:
  - Ingress
  - Egress
  ingress:
  # Autoriser depuis l'Ingress Controller
  - from:
    - namespaceSelector:
        matchLabels:
          name: ingress
    ports:
    - protocol: TCP
      port: 8080
  # Autoriser depuis les pods du m√™me namespace
  - from:
    - podSelector:
        matchLabels:
          tier: frontend
    ports:
    - protocol: TCP
      port: 8080
  egress:
  # Autoriser vers la base de donn√©es
  - to:
    - podSelector:
        matchLabels:
          app: postgres
    ports:
    - protocol: TCP
      port: 5432
  # Autoriser DNS
  - to:
    - namespaceSelector:
        matchLabels:
          name: kube-system
    - podSelector:
        matchLabels:
          k8s-app: kube-dns
    ports:
    - protocol: UDP
      port: 53
  # Autoriser Internet (APIs externes)
  - to:
    - ipBlock:
        cidr: 0.0.0.0/0
        except:
        - 169.254.169.254/32  # Metadata service AWS
        - 10.0.0.0/8          # R√©seau interne
        - 192.168.0.0/16
```

## Templates de Monitoring

### 18. ServiceMonitor pour Prometheus

Exposition des m√©triques :

```yaml
# servicemonitor-app.yaml
# ServiceMonitor pour scraping Prometheus
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: app-metrics
  namespace: apps
  labels:
    app: mon-app
    prometheus: kube-prometheus
spec:
  selector:
    matchLabels:
      app: mon-app
  endpoints:
  - port: metrics  # Port nomm√© dans le Service
    interval: 30s
    path: /metrics
    scheme: http
    # Relabeling optionnel
    relabelings:
    - sourceLabels: [__meta_kubernetes_pod_name]
      targetLabel: pod
    - sourceLabels: [__meta_kubernetes_pod_node_name]
      targetLabel: node
```

### 19. HorizontalPodAutoscaler

Mise √† l'√©chelle automatique :

```yaml
# hpa-app.yaml
# HorizontalPodAutoscaler pour scaling automatique
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: app-hpa
  namespace: apps
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: mon-app-deployment
  minReplicas: 2
  maxReplicas: 10
  metrics:
  # Scaling bas√© sur CPU
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  # Scaling bas√© sur m√©moire
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  # Scaling bas√© sur m√©trique custom (n√©cessite metrics-server)
  # - type: Pods
  #   pods:
  #     metric:
  #       name: requests_per_second
  #     target:
  #       type: AverageValue
  #       averageValue: "1000"
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300  # Attendre 5min avant scale down
      policies:
      - type: Percent
        value: 50  # R√©duire max 50% des pods
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60  # Attendre 1min avant scale up
      policies:
      - type: Percent
        value: 100  # Doubler max les pods
        periodSeconds: 60
```

## Templates Avanc√©s

### 20. DaemonSet pour Agents

D√©ployer sur chaque node :

```yaml
# daemonset-monitoring.yaml
# DaemonSet pour agent de monitoring sur chaque node
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: node-exporter
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: node-exporter
  template:
    metadata:
      labels:
        app: node-exporter
    spec:
      hostNetwork: true  # Utiliser le r√©seau de l'h√¥te
      hostPID: true      # Acc√®s aux processus de l'h√¥te
      containers:
      - name: node-exporter
        image: prom/node-exporter:latest
        ports:
        - containerPort: 9100
          hostPort: 9100
        resources:
          requests:
            memory: "30Mi"
            cpu: "100m"
          limits:
            memory: "50Mi"
            cpu: "200m"
        volumeMounts:
        - name: proc
          mountPath: /host/proc
          readOnly: true
        - name: sys
          mountPath: /host/sys
          readOnly: true
      volumes:
      - name: proc
        hostPath:
          path: /proc
      - name: sys
        hostPath:
          path: /sys
      tolerations:
      # S'ex√©cuter m√™me sur les nodes avec taints
      - effect: NoSchedule
        operator: Exists
```

### 21. Init Containers

Conteneurs d'initialisation :

```yaml
# deployment-with-init.yaml
# Deployment avec init containers
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-with-init
  namespace: apps
spec:
  replicas: 1
  selector:
    matchLabels:
      app: app-with-init
  template:
    metadata:
      labels:
        app: app-with-init
    spec:
      initContainers:
      # Attendre que la base de donn√©es soit pr√™te
      - name: wait-for-db
        image: busybox:1.35
        command:
        - sh
        - -c
        - |
          echo "Attente de la base de donn√©es..."
          until nc -z postgres-service 5432; do
            echo "Base de donn√©es non pr√™te, attente..."
            sleep 2
          done
          echo "Base de donn√©es pr√™te!"

      # Effectuer les migrations
      - name: db-migration
        image: mon-app:latest
        command: ["./migrate.sh"]
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: database-url

      # T√©l√©charger des assets
      - name: download-assets
        image: busybox:1.35
        command:
        - sh
        - -c
        - |
          echo "T√©l√©chargement des assets..."
          wget -O /shared/assets.tar.gz https://example.com/assets.tar.gz
          cd /shared && tar -xzf assets.tar.gz
          echo "Assets t√©l√©charg√©s"
        volumeMounts:
        - name: shared-data
          mountPath: /shared

      # Conteneur principal
      containers:
      - name: main-app
        image: mon-app:latest
        ports:
        - containerPort: 8080
        volumeMounts:
        - name: shared-data
          mountPath: /app/assets

      volumes:
      - name: shared-data
        emptyDir: {}
```

## Guide d'Utilisation des Templates

### Comment Utiliser ces Templates

#### 1. Copier et Adapter

```bash
# Copier le template
cp deployment-complet.yaml mon-app-deployment.yaml

# √âditer avec vos valeurs
nano mon-app-deployment.yaml

# Remplacer :
# - mon-app ‚Üí nom de votre application
# - namespace ‚Üí votre namespace
# - image ‚Üí votre image Docker
# - ports ‚Üí vos ports
# - variables d'environnement ‚Üí vos configs
```

#### 2. Valider la Syntaxe

```bash
# Valider sans appliquer
kubectl apply --dry-run=client -f mon-app-deployment.yaml

# Voir ce qui sera cr√©√©
kubectl apply --dry-run=server -f mon-app-deployment.yaml
```

#### 3. Appliquer le Manifeste

```bash
# Cr√©er/Mettre √† jour les ressources
kubectl apply -f mon-app-deployment.yaml

# V√©rifier la cr√©ation
kubectl get all -n apps
```

#### 4. D√©boguer si N√©cessaire

```bash
# Voir les √©v√©nements
kubectl describe deployment mon-app-deployment -n apps

# Voir les logs
kubectl logs -l app=mon-app -n apps

# √âditer en direct (d√©conseill√© en production)
kubectl edit deployment mon-app-deployment -n apps
```

### Conventions et Bonnes Pratiques

#### Nommage

- **Lowercase** : Utiliser des minuscules et tirets
- **Descriptif** : `app-name-resource-type`
- **Coh√©rent** : M√™me pr√©fixe pour ressources li√©es

```yaml
# Bon
name: blog-api-deployment
name: blog-api-service
name: blog-api-ingress

# Mauvais
name: MyApp
name: app_deployment
name: deploy1
```

#### Labels Recommand√©s

```yaml
metadata:
  labels:
    app.kubernetes.io/name: mon-app
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/component: backend
    app.kubernetes.io/part-of: mon-syst√®me
    app.kubernetes.io/managed-by: kubectl
    environment: production
    tier: backend
```

#### Structure des Fichiers

```bash
# Organisation recommand√©e
k8s/
‚îú‚îÄ‚îÄ base/
‚îÇ   ‚îú‚îÄ‚îÄ namespace.yaml
‚îÇ   ‚îú‚îÄ‚îÄ configmap.yaml
‚îÇ   ‚îú‚îÄ‚îÄ secret.yaml
‚îÇ   ‚îî‚îÄ‚îÄ rbac.yaml
‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îú‚îÄ‚îÄ app1/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deployment.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ service.yaml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ingress.yaml
‚îÇ   ‚îî‚îÄ‚îÄ app2/
‚îÇ       ‚îú‚îÄ‚îÄ statefulset.yaml
‚îÇ       ‚îú‚îÄ‚îÄ service.yaml
‚îÇ       ‚îî‚îÄ‚îÄ pvc.yaml
‚îú‚îÄ‚îÄ monitoring/
‚îÇ   ‚îú‚îÄ‚îÄ prometheus/
‚îÇ   ‚îî‚îÄ‚îÄ grafana/
‚îî‚îÄ‚îÄ scripts/
    ‚îú‚îÄ‚îÄ deploy-all.sh
    ‚îî‚îÄ‚îÄ cleanup.sh
```

### Ordre de D√©ploiement

L'ordre est important pour √©viter les erreurs :

1. **Namespace** - Cr√©er l'espace de travail
2. **ConfigMaps et Secrets** - Configuration n√©cessaire aux apps
3. **PersistentVolumeClaims** - Stockage requis
4. **Services** - Pour la d√©couverte de services
5. **Deployments/StatefulSets** - Les applications
6. **Ingress** - Exposition externe

```bash
# Script de d√©ploiement ordonn√©
#!/bin/bash
kubectl apply -f namespace.yaml
kubectl apply -f configmap.yaml
kubectl apply -f secret.yaml
kubectl apply -f pvc.yaml
kubectl apply -f service.yaml
kubectl apply -f deployment.yaml
kubectl apply -f ingress.yaml
```

### Gestion des Ressources

#### Limites Recommand√©es par Type d'Application

```yaml
# Application l√©g√®re (site statique, proxy)
resources:
  requests:
    memory: "64Mi"
    cpu: "50m"
  limits:
    memory: "128Mi"
    cpu: "100m"

# Application web standard
resources:
  requests:
    memory: "256Mi"
    cpu: "100m"
  limits:
    memory: "512Mi"
    cpu: "500m"

# Base de donn√©es
resources:
  requests:
    memory: "512Mi"
    cpu: "250m"
  limits:
    memory: "1Gi"
    cpu: "1000m"

# Application Java/JVM
resources:
  requests:
    memory: "1Gi"
    cpu: "500m"
  limits:
    memory: "2Gi"
    cpu: "2000m"
```

## Templates Composites

### 22. Stack Application Compl√®te

Exemple d'application compl√®te avec tous les composants :

```yaml
# stack-complete.yaml
# Stack compl√®te : Namespace + Config + Deployment + Service + Ingress
---
# 1. Namespace
apiVersion: v1
kind: Namespace
metadata:
  name: myapp-prod
  labels:
    environment: production
---
# 2. ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: myapp-config
  namespace: myapp-prod
data:
  NODE_ENV: "production"
  API_URL: "https://api.example.com"
  CACHE_TTL: "3600"
---
# 3. Secret
apiVersion: v1
kind: Secret
metadata:
  name: myapp-secret
  namespace: myapp-prod
type: Opaque
stringData:
  database-url: "postgresql://user:pass@postgres:5432/myapp"
  jwt-secret: "super-secret-jwt-key"
  api-key: "external-api-key-12345"
---
# 4. PVC pour donn√©es persistantes
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: myapp-data
  namespace: myapp-prod
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
  storageClassName: microk8s-hostpath
---
# 5. Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
  namespace: myapp-prod
  labels:
    app: myapp
    version: v1.0.0
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
        version: v1.0.0
    spec:
      containers:
      - name: myapp
        image: myregistry/myapp:1.0.0
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 3000
          name: http
        envFrom:
        - configMapRef:
            name: myapp-config
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: myapp-secret
              key: database-url
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: myapp-secret
              key: jwt-secret
        livenessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 3000
          initialDelaySeconds: 10
          periodSeconds: 5
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        volumeMounts:
        - name: data
          mountPath: /app/data
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: myapp-data
---
# 6. Service
apiVersion: v1
kind: Service
metadata:
  name: myapp-service
  namespace: myapp-prod
  labels:
    app: myapp
spec:
  type: ClusterIP
  selector:
    app: myapp
  ports:
  - port: 80
    targetPort: 3000
    protocol: TCP
    name: http
---
# 7. Ingress
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: myapp-ingress
  namespace: myapp-prod
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
spec:
  ingressClassName: nginx
  tls:
  - hosts:
    - myapp.example.com
    secretName: myapp-tls
  rules:
  - host: myapp.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: myapp-service
            port:
              number: 80
---
# 8. HPA pour autoscaling
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: myapp-hpa
  namespace: myapp-prod
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

### 23. Stack Base de Donn√©es

Configuration compl√®te pour PostgreSQL :

```yaml
# stack-postgres.yaml
# Stack PostgreSQL compl√®te avec backup
---
# Secret pour mot de passe
apiVersion: v1
kind: Secret
metadata:
  name: postgres-secret
  namespace: databases
type: Opaque
stringData:
  postgres-password: "ChangeMeSecurePassword123!"
  replication-password: "ReplicationPassword456!"
---
# ConfigMap pour configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgres-config
  namespace: databases
data:
  POSTGRES_DB: "production"
  POSTGRES_USER: "dbadmin"
  PGDATA: "/var/lib/postgresql/data/pgdata"
  # Configuration PostgreSQL
  postgresql.conf: |
    max_connections = 100
    shared_buffers = 256MB
    effective_cache_size = 1GB
    maintenance_work_mem = 64MB
    checkpoint_completion_target = 0.9
    wal_buffers = 16MB
    default_statistics_target = 100
    random_page_cost = 1.1
    effective_io_concurrency = 200
    work_mem = 4MB
    min_wal_size = 1GB
    max_wal_size = 4GB
---
# Service Headless pour StatefulSet
apiVersion: v1
kind: Service
metadata:
  name: postgres-headless
  namespace: databases
spec:
  clusterIP: None
  selector:
    app: postgres
  ports:
  - port: 5432
    targetPort: 5432
---
# Service pour acc√®s lecture/√©criture
apiVersion: v1
kind: Service
metadata:
  name: postgres
  namespace: databases
spec:
  type: ClusterIP
  selector:
    app: postgres
    role: master
  ports:
  - port: 5432
    targetPort: 5432
---
# StatefulSet PostgreSQL
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
  namespace: databases
spec:
  serviceName: postgres-headless
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
        role: master
    spec:
      containers:
      - name: postgres
        image: postgres:14-alpine
        ports:
        - containerPort: 5432
          name: postgres
        env:
        - name: POSTGRES_DB
          valueFrom:
            configMapKeyRef:
              name: postgres-config
              key: POSTGRES_DB
        - name: POSTGRES_USER
          valueFrom:
            configMapKeyRef:
              name: postgres-config
              key: POSTGRES_USER
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: postgres-password
        - name: PGDATA
          valueFrom:
            configMapKeyRef:
              name: postgres-config
              key: PGDATA
        volumeMounts:
        - name: postgres-data
          mountPath: /var/lib/postgresql/data
        - name: postgres-config-volume
          mountPath: /etc/postgresql/postgresql.conf
          subPath: postgresql.conf
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - $(POSTGRES_USER)
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - $(POSTGRES_USER)
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: postgres-config-volume
        configMap:
          name: postgres-config
  volumeClaimTemplates:
  - metadata:
      name: postgres-data
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: microk8s-hostpath
      resources:
        requests:
          storage: 20Gi
---
# CronJob pour backup quotidien
apiVersion: batch/v1
kind: CronJob
metadata:
  name: postgres-backup
  namespace: databases
spec:
  schedule: "0 2 * * *"  # 2h du matin tous les jours
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          containers:
          - name: postgres-backup
            image: postgres:14-alpine
            command:
            - /bin/sh
            - -c
            - |
              DATE=$(date +%Y%m%d_%H%M%S)
              echo "D√©marrage backup PostgreSQL - $DATE"
              PGPASSWORD=$POSTGRES_PASSWORD pg_dump \
                -h postgres \
                -U $POSTGRES_USER \
                -d $POSTGRES_DB \
                --verbose \
                --format=custom \
                --file=/backup/postgres-$DATE.dump

              # Nettoyer les backups de plus de 7 jours
              find /backup -name "postgres-*.dump" -mtime +7 -delete

              echo "Backup termin√© - postgres-$DATE.dump"
            env:
            - name: POSTGRES_DB
              valueFrom:
                configMapKeyRef:
                  name: postgres-config
                  key: POSTGRES_DB
            - name: POSTGRES_USER
              valueFrom:
                configMapKeyRef:
                  name: postgres-config
                  key: POSTGRES_USER
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: postgres-password
            volumeMounts:
            - name: backup-volume
              mountPath: /backup
          volumes:
          - name: backup-volume
            persistentVolumeClaim:
              claimName: postgres-backup-pvc
---
# PVC pour les backups
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: postgres-backup-pvc
  namespace: databases
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
  storageClassName: microk8s-hostpath
```

## Commandes Utiles pour les Templates

### Commandes de Base

```bash
# Appliquer un template
kubectl apply -f template.yaml

# Appliquer tous les fichiers d'un r√©pertoire
kubectl apply -f ./k8s/

# Appliquer avec substitution de variables
envsubst < template.yaml | kubectl apply -f -

# Supprimer les ressources d'un template
kubectl delete -f template.yaml

# Voir ce qui sera cr√©√© sans l'appliquer
kubectl apply --dry-run=client -f template.yaml -o yaml

# G√©n√©rer un template depuis une ressource existante
kubectl get deployment mon-app -o yaml > mon-app-export.yaml
```

### Commandes de D√©bogage

```bash
# Voir les √©v√©nements r√©cents
kubectl get events --sort-by='.lastTimestamp' -n apps

# D√©crire une ressource pour voir les d√©tails
kubectl describe deployment mon-app -n apps

# Voir les logs d'un pod
kubectl logs -f deployment/mon-app -n apps

# Ex√©cuter une commande dans un pod
kubectl exec -it deployment/mon-app -n apps -- /bin/bash

# Port-forward pour tester localement
kubectl port-forward service/mon-app-service 8080:80 -n apps

# Voir l'utilisation des ressources
kubectl top pods -n apps
kubectl top nodes
```

### Scripts Helper

#### Script de Validation des Templates

```bash
#!/bin/bash
# validate-templates.sh
# Valide tous les templates YAML

for file in k8s/**/*.yaml; do
    echo "Validation de $file..."
    if kubectl apply --dry-run=client -f "$file" > /dev/null 2>&1; then
        echo "‚úì $file est valide"
    else
        echo "‚úó $file contient des erreurs"
        kubectl apply --dry-run=client -f "$file"
    fi
done
```

#### Script de D√©ploiement avec Rollback

```bash
#!/bin/bash
# deploy-with-rollback.sh
# D√©ploie avec possibilit√© de rollback

NAMESPACE="apps"
DEPLOYMENT="mon-app"

# Sauvegarder l'√©tat actuel
kubectl get deployment $DEPLOYMENT -n $NAMESPACE -o yaml > rollback-$DEPLOYMENT.yaml

# Appliquer le nouveau d√©ploiement
if kubectl apply -f deployment-new.yaml; then
    echo "D√©ploiement r√©ussi"

    # Attendre que le d√©ploiement soit pr√™t
    kubectl rollout status deployment/$DEPLOYMENT -n $NAMESPACE

    # V√©rifier la sant√©
    if kubectl get pods -l app=$DEPLOYMENT -n $NAMESPACE | grep -q "0/"; then
        echo "Erreur d√©tect√©e, rollback..."
        kubectl apply -f rollback-$DEPLOYMENT.yaml
        kubectl rollout status deployment/$DEPLOYMENT -n $NAMESPACE
    else
        echo "D√©ploiement valid√©"
        rm rollback-$DEPLOYMENT.yaml
    fi
else
    echo "Erreur de d√©ploiement"
    exit 1
fi
```

## D√©pannage des Templates Courants

### Probl√®mes Fr√©quents et Solutions

#### Image Pull Errors

```yaml
# Probl√®me : ErrImagePull ou ImagePullBackOff
# Solutions :

# 1. V√©rifier le nom de l'image
image: nginx:1.21  # ‚úì Correct
# image: ngix:1.21  # ‚úó Typo

# 2. Pour images priv√©es, ajouter imagePullSecrets
spec:
  imagePullSecrets:
  - name: registry-secret
  containers:
  - name: app
    image: private-registry.com/app:latest

# 3. Cr√©er le secret pour registry priv√©
kubectl create secret docker-registry registry-secret \
  --docker-server=private-registry.com \
  --docker-username=user \
  --docker-password=pass \
  --docker-email=email@example.com
```

#### CrashLoopBackOff

```yaml
# Probl√®me : Le conteneur red√©marre constamment
# Solutions :

# 1. V√©rifier les logs
kubectl logs pod-name -n namespace --previous

# 2. Augmenter les d√©lais de probe
livenessProbe:
  initialDelaySeconds: 60  # Plus de temps pour d√©marrer
  periodSeconds: 20
  timeoutSeconds: 10
  failureThreshold: 5

# 3. V√©rifier les variables d'environnement requises
env:
- name: REQUIRED_VAR
  value: "must-be-set"
```

#### Pending Pods

```yaml
# Probl√®me : Pods restent en Pending
# Solutions :

# 1. V√©rifier les ressources disponibles
kubectl describe nodes
kubectl top nodes

# 2. R√©duire les demandes de ressources
resources:
  requests:
    memory: "64Mi"   # R√©duire si n√©cessaire
    cpu: "50m"       # R√©duire si n√©cessaire

# 3. V√©rifier le PVC
kubectl get pvc -n namespace
kubectl describe pvc pvc-name -n namespace
```

## Conclusion

Cette collection de templates constitue une base solide pour d√©ployer vos applications sur MicroK8s. Les points cl√©s √† retenir :

1. **Commencez simple** : Utilisez les templates de base et complexifiez progressivement
2. **Testez toujours** : Utilisez `--dry-run` avant d'appliquer en production
3. **Versionnez vos manifestes** : Gardez une trace des changements avec Git
4. **Documentez vos modifications** : Ajoutez des commentaires pour expliquer les choix
5. **Respectez les conventions** : Nommage coh√©rent et labels standardis√©s

Ces templates sont des points de d√©part que vous devez adapter √† vos besoins sp√©cifiques. N'h√©sitez pas √† les modifier, les combiner et les enrichir selon votre exp√©rience et vos requirements.

---

*Note : Les templates fournis utilisent des valeurs par d√©faut s√©curis√©es mais g√©n√©riques. Assurez-vous de les personnaliser avec vos propres valeurs, notamment pour les mots de passe, les noms de domaine et les configurations sp√©cifiques √† votre environnement.*

‚è≠Ô∏è
