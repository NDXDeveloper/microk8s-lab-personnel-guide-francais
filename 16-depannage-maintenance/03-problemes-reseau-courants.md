üîù Retour au [Sommaire](/SOMMAIRE.md)

# 16.3 Probl√®mes r√©seau courants

## Introduction aux d√©fis r√©seau dans Kubernetes

Le r√©seau est l'une des parties les plus complexes de Kubernetes, et par cons√©quent, une source fr√©quente de probl√®mes. Dans MicroK8s, bien que le r√©seau soit simplifi√© par rapport √† une installation Kubernetes compl√®te, vous rencontrerez tout de m√™me des d√©fis. Cette section vous aidera √† comprendre, diagnostiquer et r√©soudre les probl√®mes r√©seau les plus courants, depuis les simples erreurs de connectivit√© jusqu'aux probl√®mes plus subtils de routage et de DNS.

## Comprendre l'architecture r√©seau de MicroK8s

### Vue d'ensemble du mod√®le r√©seau

Avant de plonger dans les probl√®mes, il est essentiel de comprendre comment fonctionne le r√©seau dans MicroK8s. Le mod√®le r√©seau Kubernetes repose sur plusieurs principes fondamentaux :

**Communication pod-to-pod** : Tous les pods peuvent communiquer entre eux sans NAT (Network Address Translation). Chaque pod re√ßoit sa propre adresse IP dans un r√©seau virtuel interne. Dans MicroK8s, ce r√©seau utilise g√©n√©ralement la plage 10.1.0.0/16 par d√©faut.

**Services et endpoints** : Les Services Kubernetes fournissent une abstraction stable pour acc√©der aux pods. Ils utilisent un syst√®me de proxy (kube-proxy) pour router le trafic vers les pods appropri√©s. Les Services obtiennent des IPs dans une plage diff√©rente, typiquement 10.152.183.0/24.

**DNS interne** : CoreDNS fournit la r√©solution de noms √† l'int√©rieur du cluster. Chaque service est accessible via un nom DNS de la forme `<service>.<namespace>.svc.cluster.local`.

**Acc√®s externe** : L'acc√®s depuis l'ext√©rieur du cluster se fait via NodePort, LoadBalancer (avec MetalLB dans MicroK8s), ou Ingress Controller.

### Composants r√©seau critiques

Les composants suivants sont essentiels au bon fonctionnement du r√©seau :

- **Calico/Flannel** : Le plugin CNI (Container Network Interface) qui g√®re le r√©seau des pods
- **CoreDNS** : Le serveur DNS interne du cluster
- **kube-proxy** : G√®re les r√®gles iptables pour le routage des services
- **Ingress Controller** : G√®re l'acc√®s HTTP/HTTPS externe

## Probl√®me 1 : Les pods ne peuvent pas communiquer entre eux

### Sympt√¥mes

- Les pods ne peuvent pas se ping mutuellement
- Les connexions TCP/UDP √©chouent entre pods
- Messages d'erreur type "connection refused" ou "no route to host"

### Diagnostic

Commencez par v√©rifier la configuration r√©seau de base :

```bash
# V√©rifier que le plugin CNI est actif
microk8s kubectl get pods -n kube-system | grep calico

# V√©rifier les interfaces r√©seau dans un pod
microk8s kubectl exec -it <pod-name> -- ip addr show

# Tester la connectivit√© entre deux pods
# Depuis le pod A, obtenir son IP
microk8s kubectl get pod <pod-a> -o wide

# Depuis le pod B, ping le pod A
microk8s kubectl exec -it <pod-b> -- ping <ip-pod-a>
```

V√©rifiez les Network Policies qui pourraient bloquer le trafic :

```bash
# Lister toutes les Network Policies
microk8s kubectl get networkpolicies --all-namespaces

# D√©tailler une policy sp√©cifique
microk8s kubectl describe networkpolicy <policy-name> -n <namespace>
```

### R√©solution

Si le plugin CNI n'est pas fonctionnel :

```bash
# Red√©marrer Calico
microk8s kubectl delete pods -n kube-system -l k8s-app=calico-node
# Les pods seront recr√©√©s automatiquement

# Si le probl√®me persiste, v√©rifier les logs
microk8s kubectl logs -n kube-system -l k8s-app=calico-node
```

Pour les probl√®mes de Network Policy :

```bash
# Temporairement supprimer une policy pour tester
microk8s kubectl delete networkpolicy <policy-name> -n <namespace>

# Cr√©er une policy qui permet tout le trafic (pour debug uniquement)
cat <<EOF | microk8s kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-all
  namespace: <namespace>
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - {}
  egress:
  - {}
EOF
```

## Probl√®me 2 : Le DNS ne fonctionne pas

### Sympt√¥mes

- Impossible de r√©soudre les noms de services
- Erreurs "nslookup: can't resolve"
- Les pods ne peuvent pas acc√©der aux services par leur nom

### Diagnostic

Testez d'abord le DNS depuis un pod de test :

```bash
# Cr√©er un pod de debug avec des outils r√©seau
microk8s kubectl run dnstest --image=busybox:latest --rm -it -- /bin/sh

# Dans le pod, tester les r√©solutions DNS
nslookup kubernetes.default
nslookup google.com
cat /etc/resolv.conf
```

V√©rifiez l'√©tat de CoreDNS :

```bash
# V√©rifier que CoreDNS est en cours d'ex√©cution
microk8s kubectl get pods -n kube-system -l k8s-app=kube-dns

# Examiner les logs de CoreDNS
microk8s kubectl logs -n kube-system -l k8s-app=kube-dns --tail=50

# V√©rifier la configuration de CoreDNS
microk8s kubectl get configmap coredns -n kube-system -o yaml
```

Testez la r√©solution DNS directement :

```bash
# Obtenir l'IP du service DNS
microk8s kubectl get service -n kube-system kube-dns

# Tester avec dig ou nslookup directement vers CoreDNS
microk8s kubectl run test-dns --image=tutum/dnsutils --rm -it -- /bin/sh
# Dans le pod:
nslookup kubernetes.default 10.152.183.10  # Remplacer par l'IP de kube-dns
dig @10.152.183.10 kubernetes.default.svc.cluster.local
```

### R√©solution

Pour r√©parer CoreDNS :

```bash
# Red√©marrer CoreDNS
microk8s kubectl rollout restart deployment/coredns -n kube-system

# Si CoreDNS crash en boucle, v√©rifier les ressources
microk8s kubectl describe pod -n kube-system -l k8s-app=kube-dns

# Augmenter les ressources si n√©cessaire
microk8s kubectl edit deployment coredns -n kube-system
# Modifier les sections resources.requests et resources.limits
```

Pour les probl√®mes de configuration DNS dans les pods :

```bash
# V√©rifier la configuration DNS du pod
microk8s kubectl get pod <pod-name> -o yaml | grep -A 10 dnsPolicy

# Forcer une politique DNS sp√©cifique
# Dans le manifest du pod, ajouter:
spec:
  dnsPolicy: ClusterFirst  # ou Default, None, ClusterFirstWithHostNet
  dnsConfig:
    nameservers:
      - 10.152.183.10  # IP de CoreDNS
    searches:
      - default.svc.cluster.local
      - svc.cluster.local
      - cluster.local
```

## Probl√®me 3 : Les Services ne sont pas accessibles

### Sympt√¥mes

- Impossible d'acc√©der √† un service via son ClusterIP
- Le service ne route pas vers les pods
- Erreur "connection refused" lors de l'acc√®s au service

### Diagnostic

V√©rifiez d'abord la configuration du service :

```bash
# Lister les services et leurs endpoints
microk8s kubectl get services -o wide
microk8s kubectl get endpoints

# V√©rifier qu'un service a des endpoints
microk8s kubectl get endpoints <service-name>

# D√©tailler le service
microk8s kubectl describe service <service-name>
```

Testez l'acc√®s au service :

```bash
# Cr√©er un pod de test
microk8s kubectl run test-svc --image=nicolaka/netshoot --rm -it -- /bin/bash

# Dans le pod, tester l'acc√®s au service
curl http://<service-name>.<namespace>.svc.cluster.local:<port>
nc -zv <service-name>.<namespace>.svc.cluster.local <port>
```

V√©rifiez que les s√©lecteurs correspondent :

```bash
# Comparer les labels du service avec ceux des pods
echo "Service selector:"
microk8s kubectl get service <service-name> -o jsonpath='{.spec.selector}'

echo -e "\nPod labels:"
microk8s kubectl get pods --show-labels
```

### R√©solution

Si les endpoints sont vides :

```bash
# V√©rifier que les labels des pods correspondent au s√©lecteur du service
microk8s kubectl label pod <pod-name> <label-key>=<label-value>

# Recr√©er le service avec les bons s√©lecteurs
microk8s kubectl delete service <service-name>
microk8s kubectl expose deployment <deployment-name> --port=<port> --target-port=<target-port>
```

Pour les probl√®mes de kube-proxy :

```bash
# V√©rifier les r√®gles iptables (sur le n≈ìud h√¥te)
sudo iptables -t nat -L -n | grep <service-cluster-ip>

# Red√©marrer kube-proxy (int√©gr√© dans kubelite)
sudo systemctl restart snap.microk8s.daemon-kubelite

# V√©rifier les logs de kube-proxy
journalctl -u snap.microk8s.daemon-kubelite | grep proxy
```

## Probl√®me 4 : L'Ingress ne fonctionne pas

### Sympt√¥mes

- Impossible d'acc√©der aux applications depuis l'ext√©rieur
- Erreur 404 ou 502 Bad Gateway
- Le certificat SSL ne fonctionne pas

### Diagnostic

V√©rifiez l'√©tat de l'Ingress Controller :

```bash
# V√©rifier que l'addon ingress est activ√©
microk8s status | grep ingress

# V√©rifier les pods de l'ingress controller
microk8s kubectl get pods -n ingress

# Examiner les logs de l'ingress controller
microk8s kubectl logs -n ingress -l name=nginx-ingress-microk8s
```

V√©rifiez la configuration Ingress :

```bash
# Lister tous les Ingress
microk8s kubectl get ingress --all-namespaces

# D√©tailler un Ingress sp√©cifique
microk8s kubectl describe ingress <ingress-name> -n <namespace>

# V√©rifier que l'Ingress a une adresse IP
microk8s kubectl get ingress <ingress-name> -n <namespace>
```

Testez la r√©solution et l'acc√®s :

```bash
# V√©rifier la r√©solution DNS externe
nslookup <your-domain>

# Tester l'acc√®s direct √† l'Ingress Controller
curl -H "Host: <your-domain>" http://<node-ip>

# Avec SSL/TLS
curl -k -H "Host: <your-domain>" https://<node-ip>

# Voir les backends configur√©s
microk8s kubectl exec -n ingress <nginx-pod> -- cat /etc/nginx/nginx.conf | grep -A 5 "upstream"
```

### R√©solution

Pour les probl√®mes de routage Ingress :

```bash
# V√©rifier que le service backend existe et a des endpoints
microk8s kubectl get endpoints <backend-service> -n <namespace>

# Recr√©er l'Ingress avec la bonne configuration
cat <<EOF | microk8s kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: test-ingress
  namespace: <namespace>
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: <your-domain>
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: <service-name>
            port:
              number: <port>
EOF
```

Pour les probl√®mes SSL/TLS :

```bash
# V√©rifier le certificat
microk8s kubectl get certificate --all-namespaces
microk8s kubectl describe certificate <cert-name> -n <namespace>

# V√©rifier le secret TLS
microk8s kubectl get secret <tls-secret> -n <namespace>
microk8s kubectl get secret <tls-secret> -n <namespace> -o yaml

# Forcer le renouvellement avec cert-manager
microk8s kubectl delete certificate <cert-name> -n <namespace>
# Le certificat sera recr√©√© automatiquement
```

## Probl√®me 5 : Impossible d'acc√©der √† Internet depuis les pods

### Sympt√¥mes

- Les pods ne peuvent pas t√©l√©charger des images
- Impossible de faire des requ√™tes HTTP vers l'ext√©rieur
- Les mises √† jour de packages √©chouent

### Diagnostic

Testez la connectivit√© externe :

```bash
# Test depuis un pod
microk8s kubectl run test-internet --image=busybox --rm -it -- /bin/sh

# Dans le pod:
ping 8.8.8.8  # Test connectivit√© IP
nslookup google.com  # Test DNS externe
wget -O- http://www.google.com  # Test HTTP
```

V√©rifiez la configuration NAT et le forwarding :

```bash
# Sur le n≈ìud h√¥te
# V√©rifier que le forwarding IP est activ√©
cat /proc/sys/net/ipv4/ip_forward  # Doit retourner 1

# V√©rifier les r√®gles de NAT
sudo iptables -t nat -L POSTROUTING -n -v

# V√©rifier la route par d√©faut dans un pod
microk8s kubectl exec -it <pod-name> -- ip route
```

### R√©solution

Activer le forwarding IP si n√©cessaire :

```bash
# Activation temporaire
sudo sysctl -w net.ipv4.ip_forward=1

# Activation permanente
echo "net.ipv4.ip_forward=1" | sudo tee -a /etc/sysctl.conf
sudo sysctl -p
```

Corriger les r√®gles de NAT :

```bash
# Ajouter une r√®gle de masquerade si manquante
sudo iptables -t nat -A POSTROUTING -s 10.1.0.0/16 ! -d 10.1.0.0/16 -j MASQUERADE

# Sauvegarder les r√®gles
sudo iptables-save | sudo tee /etc/iptables/rules.v4
```

Pour les probl√®mes de proxy d'entreprise :

```bash
# Configurer le proxy pour MicroK8s
sudo nano /var/snap/microk8s/current/args/containerd-env

# Ajouter:
HTTP_PROXY=http://proxy.company.com:8080
HTTPS_PROXY=http://proxy.company.com:8080
NO_PROXY=10.0.0.0/8,192.168.0.0/16,127.0.0.1,localhost,.cluster.local

# Red√©marrer MicroK8s
microk8s stop
microk8s start
```

## Probl√®me 6 : Performances r√©seau d√©grad√©es

### Sympt√¥mes

- Latence √©lev√©e entre les pods
- D√©bit r√©seau faible
- Timeouts fr√©quents

### Diagnostic

Testez les performances r√©seau :

```bash
# Installer iperf3 pour les tests de bande passante
# Pod serveur
microk8s kubectl run iperf-server --image=networkstatic/iperf3 -- -s

# Pod client
microk8s kubectl run iperf-client --image=networkstatic/iperf3 --rm -it -- -c <server-pod-ip>

# Test de latence
microk8s kubectl exec -it <pod-name> -- ping -c 100 <target-pod-ip>
```

V√©rifiez l'utilisation des ressources :

```bash
# CPU et m√©moire du syst√®me
top
htop

# Utilisation r√©seau
iftop
nethogs

# Statistiques des interfaces
ip -s link show
```

Analysez la configuration MTU :

```bash
# V√©rifier le MTU des interfaces
ip link show

# Dans un pod
microk8s kubectl exec -it <pod-name> -- ip link show

# Test de MTU
microk8s kubectl exec -it <pod-name> -- ping -M do -s 1472 <target-ip>
```

### R√©solution

Optimiser les param√®tres r√©seau :

```bash
# Ajuster le MTU si n√©cessaire
sudo ip link set dev cni0 mtu 1450

# Configuration permanente dans Calico
microk8s kubectl edit configmap calico-config -n kube-system
# Modifier: "mtu": "1450"

# Red√©marrer Calico
microk8s kubectl rollout restart daemonset/calico-node -n kube-system
```

Optimisation des param√®tres kernel :

```bash
# Augmenter les buffers r√©seau
sudo sysctl -w net.core.rmem_max=134217728
sudo sysctl -w net.core.wmem_max=134217728
sudo sysctl -w net.ipv4.tcp_rmem="4096 87380 134217728"
sudo sysctl -w net.ipv4.tcp_wmem="4096 65536 134217728"

# Optimiser les connexions
sudo sysctl -w net.core.somaxconn=1024
sudo sysctl -w net.ipv4.tcp_max_syn_backlog=2048
```

## Probl√®me 7 : Port forwarding ne fonctionne pas

### Sympt√¥mes

- `kubectl port-forward` √©choue ou se d√©connecte
- Impossible d'acc√©der aux services via port-forward
- Connection reset lors de l'utilisation

### Diagnostic

Testez le port-forward :

```bash
# Tentative de port-forward
microk8s kubectl port-forward pod/<pod-name> 8080:80

# Dans un autre terminal
curl http://localhost:8080

# Avec plus de verbosit√© pour debug
microk8s kubectl port-forward pod/<pod-name> 8080:80 -v=9
```

V√©rifiez les ports locaux :

```bash
# V√©rifier si le port est d√©j√† utilis√©
sudo netstat -tlnp | grep 8080
sudo lsof -i :8080
```

### R√©solution

Pour les probl√®mes de port-forward :

```bash
# Utiliser une adresse IP sp√©cifique
microk8s kubectl port-forward --address 0.0.0.0 pod/<pod-name> 8080:80

# Pour un service au lieu d'un pod
microk8s kubectl port-forward service/<service-name> 8080:80

# Augmenter le timeout
microk8s kubectl port-forward pod/<pod-name> 8080:80 --pod-running-timeout=5m
```

Alternative avec socat :

```bash
# Cr√©er un pod socat pour le forwarding
microk8s kubectl run socat-proxy --image=alpine/socat --port=8080 \
  -- tcp-listen:8080,fork,reuseaddr tcp-connect:<service-name>:80

# Exposer ce pod
microk8s kubectl expose pod socat-proxy --type=NodePort --port=8080
```

## Outils de diagnostic r√©seau avanc√©s

### Utilisation de tcpdump

Pour une analyse approfondie du trafic :

```bash
# Capturer le trafic sur l'interface CNI
sudo tcpdump -i cni0 -w capture.pcap

# Capturer dans un pod (n√©cessite des privil√®ges)
microk8s kubectl run tcpdump --image=corfr/tcpdump --privileged=true \
  --overrides='{"spec":{"hostNetwork":true}}' -- -i any -w /tmp/capture.pcap

# Filtrer par port
sudo tcpdump -i any port 80

# Filtrer par IP
sudo tcpdump -i any host 10.1.1.10
```

### Utilisation de netshoot

Netshoot est une image Docker contenant de nombreux outils r√©seau :

```bash
# D√©ployer netshoot
microk8s kubectl run netshoot --image=nicolaka/netshoot --rm -it -- /bin/bash

# Outils disponibles dans netshoot:
# - curl, wget
# - dig, nslookup, host
# - ping, traceroute, mtr
# - iperf3, netcat
# - tcpdump, tshark
# - ss, netstat
```

### Analyse avec Wireshark

Pour une analyse graphique :

```bash
# Capturer et analyser avec Wireshark
sudo tcpdump -i cni0 -w /tmp/k8s-capture.pcap
# Transf√©rer le fichier sur votre machine locale
# Ouvrir avec Wireshark pour analyse

# Filtres Wireshark utiles:
# - tcp.port == 80
# - http
# - dns
# - tcp.flags.reset == 1  # Pour voir les connexions rejet√©es
```

## Scripts de diagnostic r√©seau

### Script de test complet

Cr√©ez un script pour automatiser les tests r√©seau :

```bash
#!/bin/bash
# network-diagnostic.sh

echo "=== Diagnostic R√©seau MicroK8s ==="
echo "Date: $(date)"
echo ""

echo "1. √âtat des composants r√©seau"
microk8s kubectl get pods -n kube-system | grep -E "calico|dns|proxy"

echo -e "\n2. Services et Endpoints"
microk8s kubectl get services --all-namespaces
echo "---"
microk8s kubectl get endpoints --all-namespaces

echo -e "\n3. Test DNS"
microk8s kubectl run dnstest --image=busybox --rm -it --restart=Never -- \
  nslookup kubernetes.default

echo -e "\n4. Test de connectivit√© externe"
microk8s kubectl run nettest --image=busybox --rm -it --restart=Never -- \
  ping -c 3 8.8.8.8

echo -e "\n5. R√®gles Ingress"
microk8s kubectl get ingress --all-namespaces

echo -e "\n6. Network Policies"
microk8s kubectl get networkpolicies --all-namespaces

echo -e "\n7. Configuration r√©seau du n≈ìud"
ip addr show
echo "---"
ip route show

echo -e "\n8. R√®gles iptables (NAT)"
sudo iptables -t nat -L POSTROUTING -n | head -20
```

### Script de test de connectivit√©

```bash
#!/bin/bash
# test-connectivity.sh

NAMESPACE=${1:-default}
POD1=$2
POD2=$3

if [ -z "$POD1" ] || [ -z "$POD2" ]; then
    echo "Usage: $0 [namespace] pod1 pod2"
    exit 1
fi

echo "Test de connectivit√© entre $POD1 et $POD2 dans namespace $NAMESPACE"

# Obtenir les IPs
IP1=$(microk8s kubectl get pod $POD1 -n $NAMESPACE -o jsonpath='{.status.podIP}')
IP2=$(microk8s kubectl get pod $POD2 -n $NAMESPACE -o jsonpath='{.status.podIP}')

echo "IP de $POD1: $IP1"
echo "IP de $POD2: $IP2"

# Test ping
echo -e "\nTest ping $POD1 -> $POD2"
microk8s kubectl exec -n $NAMESPACE $POD1 -- ping -c 3 $IP2

echo -e "\nTest ping $POD2 -> $POD1"
microk8s kubectl exec -n $NAMESPACE $POD2 -- ping -c 3 $IP1

# Test ports si possible
echo -e "\nTest de port (si nc disponible)"
microk8s kubectl exec -n $NAMESPACE $POD1 -- sh -c "command -v nc && nc -zv $IP2 80"
```

## Pr√©vention des probl√®mes r√©seau

### Bonnes pratiques

1. **Monitoring proactif** : Mettez en place des alertes pour d√©tecter les probl√®mes r√©seau avant qu'ils n'impactent les utilisateurs

2. **Documentation** : Maintenez une documentation de votre architecture r√©seau, incluant les plages IP, les services expos√©s, et les r√®gles de firewall

3. **Tests r√©guliers** : Ex√©cutez des tests de connectivit√© automatis√©s p√©riodiquement

4. **Isolation** : Utilisez les Network Policies pour segmenter le r√©seau et limiter l'impact des probl√®mes

5. **Ressources suffisantes** : Assurez-vous que les composants r√©seau (CoreDNS, Ingress Controller) ont suffisamment de ressources

### Configuration pr√©ventive

```yaml
# health-check-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: network-health-check
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: network-health
  template:
    metadata:
      labels:
        app: network-health
    spec:
      containers:
      - name: healthcheck
        image: busybox
        command: ["/bin/sh"]
        args: ["-c", "while true; do nslookup kubernetes.default; sleep 30; done"]
        resources:
          limits:
            memory: "64Mi"
            cpu: "50m"
```

## Conclusion

Les probl√®mes r√©seau dans Kubernetes peuvent sembler intimidants au d√©but, mais avec une approche m√©thodique et les bons outils, ils deviennent g√©rables. La cl√© est de comprendre l'architecture r√©seau, de savoir o√π chercher les informations de diagnostic, et d'avoir une bo√Æte √† outils de commandes et de techniques pr√™tes √† l'emploi. N'oubliez pas que la plupart des probl√®mes r√©seau ont des causes communes : mauvaise configuration DNS, s√©lecteurs de service incorrects, ou r√®gles de firewall trop restrictives. En gardant ces points √† l'esprit et en utilisant les techniques pr√©sent√©es dans cette section, vous serez bien √©quip√© pour r√©soudre la majorit√© des probl√®mes r√©seau que vous rencontrerez dans votre cluster MicroK8s.

‚è≠Ô∏è
